---
icon: terminal
tags: [tutorial, llama2]
order: 40
---

# 6. 마무리 

지금까지 MoAI 플랫폼에서 [Llama2 13B](https://huggingface.co/meta-llama/Llama-2-13b-hf) 로 텍스트 요약 작업을 할 때 fine-tuning 하는 과정을 살펴보았습니다. Llama와 같은 오픈 소스 대형 언어 모델(LLM)은 요약, 질문 답변 등 다양한 자연어 처리 작업에 활용될 수 있습니다. **MoAI 플랫폼을 사용한다면 여러분이 필요한 GPU 수를 코드 변경 없이 손쉽게 설정할 수 있습니다.**
LLaMA 2와 같은 대형 언어 모델, 미세 조정 기술, MoAI 플랫폼의 가용성 덕분에 누구나 강력한 AI 애플리케이션을 개발할 수 있게 되었습니다. 따라서 이 튜토리얼에서 수행해 본 과정을 바탕으로 여러분만의 데이터로 새로운 모델을 빠르고 쉽게 개발해 보세요. 

이 튜토리얼이나 MoAI Platform에 관련하여 궁금한 점이나 문의 사항이 있는 경우 Moreh(support@moreh.io)에 문의하시기 바랍니다.

## 더 알아보기

- *[MoAI Platform의 자동병렬화 기능,  Advanced Parallelization (AP)](https://docs.moreh.io/ko/supported_documents/ap/)*
- [Llama3 8B Fine-tuning](../../Tutorials/Llama3_8B_Tutorial/index.md)
- [Llama3 70B Fine-tuning](../../Tutorials/llama3_70b_tutorial/index.md)
- [Mistral Fine-tuning](../../Tutorials/Mistral_Tutorial/index.md)
- [GPT Fine-tuning](../../Tutorials/GPT_Tutorial/index.md)
- [Qwen Fine-tuning](../../Tutorials/Qwen_Tutorial/index.md)
- [Baichuan2 Fine-tuning](../../Tutorials/Baichuan2_Tutorial/index.md)
