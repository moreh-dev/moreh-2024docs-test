---
icon: terminal
tags: [tutorial, llama3_70b]
order: 40
---

# 4. 마무리 

지금까지 MoAI Platform에서 Llama3-70b 모델을 fine-tuning하는 과정을 살펴 보았습니다. MoAI 플랫폼을 사용한다면 여러분이 1개, 4개, 100개 등 모든 개수의 GPU를 코드 변경 없이 손쉽게 설정할 수 있습니다. 여러분만의 데이터로 새로운 모델을 빠르고 쉽게 개발해 보세요. 

이 튜토리얼이나 MoAI Platform에 관련하여 궁금한 점이나 문의 사항이 있는 경우 Moreh(support@moreh.io)에 문의하시기 바랍니다.

## 더 알아보기

- *[MoAI Platform의 자동병렬화 기능,  Advanced Parallelization (AP)](https://docs.moreh.io/ko/supported_documents/ap/)*
- [GPT Fine-tuning](../gpt_tutorial/index.md)
- [Llama3 8B Fine-tuning](../llama3_8b_tutorial/index.md)
- [Mistral Fine-tuning](../mistral_tutorial/index.md)
- [Baichuan2 Fine-tuning](../baichuan2_tutorial/index.md)
- [Qwen Fine-tuning](../qwen_Tutorial/index.md)