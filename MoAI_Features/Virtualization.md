---
icon: note
tags: [guide]
order: 200
---


# 가상화(Virtualization)에 대해서

유저는 MoAI Platform의 가상화 기능을 통해 수백 개의 GPU를 마치 하나의 단일한 가속기를 다루는 것과 같이 사용할 수 있습니다. 유저는 이를 통하여 수백 대의 GPU에 해당하는 자원과 계산 리소스를 사용함과 동시에 복잡한 GPU 클러스터 관리의 부담을 줄일 수 있습니다. 

먼저, 널리 사용되는 NVIDIA GPU 환경과의 비교를 통해 MoAI Platform에서 가상화된 가속기를 어떻게 확인할 수 있는지 알아보겠습니다. NVIDIA GPU 환경에서  `nvidia-smi` 를 사용하였을 경우 우리는 다음과 같은 화면을 통해 현재 사용 가능한 NVIDA GPU의 정보를 확인할 수 있습니다. 

```bash
$ nvidia-smi
Tue May  7 16:39:18 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100 80G...  On   | 00000000:01:00.0 Off |                    0 |
| N/A   63C    P0   170W / 300W |  46855MiB / 81920MiB |    100%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   2022772      C   python                          46853MiB | 
+-----------------------------------------------------------------------------+ 
```

이 예시와 같이 `nvidia-smi` 를 통해 보여지는 각각의 GPU 정보는 현재 유저가 사용할 수 있는 물리적인 GPU 장비의 정보를 의미합니다.

MoAI Platform에서 `moreh-smi` 를 사용하면 마찬가지로 유저가 현재 사용할 수 있는 가속기의 정보를 확인할 수 있습니다. 

```bash
$ moreh-smi
16:28:42 May 07, 2024 
+-----------------------------------------------------------------------------------------------------+
|                                                    Current Version: 24.5.0  Latest Version: 24.5.0  |
+-----------------------------------------------------------------------------------------------------+
|  Device  |        Name         |       Flavor     |  Memory Usage  |  Total Memory  |  Utilization  |
+=====================================================================================================+
|  * 0     |  MoAI Accelerator   |  8xLarge.4096GB  |  -             |  -             |  -            |
+-----------------------------------------------------------------------------------------------------+
```

`moreh-smi` 의 결과에서 유저는 마치 4096GB의 메모리를 갖는 단일한 가속기를 사용하는 것 처럼 보입니다. 차이점이 있다면, 이는 사실 수십~수백개의 물리적인 GPU로 이루어진 GPU 클러스터가 하나의 가속기로 가상화된 결과라는 것입니다. 

MoAI Platform상에서 PyTorch나 Tensorflow와 같은 딥러닝 프레임워크를 사용할 때에도 마찬가지로 유저는 하나의 단일한 가속기를 사용하는 것으로 간주됩니다. 유저는 Pytorch의 `cuda()` 와 같은 API를 그대로 사용하여 가상화된 가속기를 사용할 수 있습니다. 

```bash
$ python
Python 3.8.19 (default, Mar 20 2024, 19:58:24) 
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> torch.cuda.device_count()
1
>>> 
```

위와 같이 pytorch에서 기존 cuda API를 그대로 사용하여 현재 사용 가능한 가속기 갯수를 확인하였을 경우, 1이라는 결과가 나오는 것을 확인할 수 있습니다. 

![](/img/moreh_virtual_device.gif)

여기서 알아두셔야 할 것은, 실제 유저가 사용하는 노드(front node)에는 물리적인 GPU가 없다는 사실입니다. 유저가 PyTorch와 같은 딥러닝 프레임워크에서 `.cuda()` 와 같은 API를 통해 GPU 가속기를 사용하고자 하면 MoAI Platform은 유저가 사용할 수 있는 GPU 클러스터를  front node가 사용할 수 있도록 자동으로 할당합니다. 유저가 딥러닝 프레임워크를 사용하여 모델 학습 및 추론 작업을 수행할 시 MoAI Platform에서는 할당된 GPU 클러스터를 단일한 가속기로 간주하여 사용할 수 있도록 병렬화와 같은 기법을 자동으로 적용합니다.