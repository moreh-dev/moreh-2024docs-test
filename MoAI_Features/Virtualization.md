---
icon: cpu
tags: [guide]
order: 10
---

# GPU Virtualization

MoAI Platform의 가상화 기능을 통해 사용자는 수백 개의 GPU를 단일 가속기처럼 사용할 수 있습니다. 

이를 통해 수백 대의 GPU에 해당하는 계산 리소스를 활용하면서도 복잡한 GPU 클러스터 관리의 부담을 줄일 수 있습니다.

**`moreh-smi`** 명령어를 통해 현재 환경에서 사용 가능한 가상화된 가속기를 확인할 수 있습니다.

```bash
$ moreh-smi
16:28:42 May 07, 2024
+-----------------------------------------------------------------------------------------------------+
|                                                    Current Version: 24.5.0  Latest Version: 24.5.0  |
+-----------------------------------------------------------------------------------------------------+
|  Device  |        Name         |       Model      |  Memory Usage  |  Total Memory  |  Utilization  |
+=====================================================================================================+
|  * 0     |  MoAI Accelerator   |  4xLarge.2048GB  |  1064128 MiB   |  2096640 MiB   |  100 %        |
+-----------------------------------------------------------------------------------------------------+

Processes:
+--------------------------------------------------------------------------------------+
|  Device  |  Job ID  |    PID    |               Process             |  Memory Usage  |
+======================================================================================+
|       0  |  977195  |  1968084  |  python tutorial/train_llama2.py  |  1064128 MiB   |
+--------------------------------------------------------------------------------------+
```

예를 들어, **`moreh-smi`**의 출력 결과는 사용자가 마치 2048GB의 메모리를 가진 단일 가속기(MoAI Accelerator)를 사용하는 것처럼 보입니다. MoAI Platform은 수십에서 수백 개의 물리적 GPU로 이루어진 클러스터를 별도의 작업 없이 단일 가속기처럼 사용할 수 있도록 가상화해줍니다.

MoAI Platform에서 PyTorch나 TensorFlow 같은 딥러닝 프레임워크를 사용하는 경우에도 사용자는 단일 가속기를 사용하는 것처럼 작업할 수 있습니다. 사용자는 PyTorch의 **`cuda()`** 같은 API를 그대로 사용하여 가상화된 가속기를 활용할 수 있습니다.

```bash
$ python
Python 3.8.19 (default, Mar 20 2024, 19:58:24) 
[GCC 11.2.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> torch.cuda.device_count()
1
>>> 
```

예를 들어 위와 같이, PyTorch에서 기존 **`cuda`** API를 사용하여 현재 사용 가능한 가속기 수를 확인하면, 1이라는 결과가 나옵니다.

여기서 알아두셔야 할 것은, 실제 유저가 사용하는 노드(front node)에는 물리적인 GPU가 없다는 사실입니다. 사용자가 PyTorch와 같은 딥러닝 프레임워크에서 **`.cuda()`** 같은 API를 통해 GPU 가속기를 사용하려고 하면 MoAI Platform은 백노드(backnode)에 있는 GPU 클러스터 자원을 자동으로 할당합니다.

딥러닝 프레임워크를 통해 본격적인 모델 학습 및 추론을 진행할 때, MoAI Platform은 모델 병렬화와 같은 기법을 **자동으로** 적용하여 사용자가 GPU 클러스터를 하나의 가속기로 간주하여 사용할 수 있도록 합니다. 

아래 그림은 사용자가 MoAI Accelerator를 사용할 때 사용 중인 노드와 실제로 할당된 GPU 클러스터 간의 관계를 보여줍니다.

--![](/img_ov/v_3.png)

MoAI Accelerator를 구성하는 물리적인 GPU의 사용 현황은 moreh-smi -p 명령어를 통해 확인할 수 있습니다.


```bash
$ moreh-smi -p
16:53:21 May 07, 2024 
+--------------------------------------------------------------------------------------+
|  Dev  |  Location  |  Dev Temp  |  Mem Temp  |  Dev Util  |  Mem Util  |  Mem Usage  |
+======================================================================================+
|    0  |  back24:0  |    50 C    |    59 C    |   100 %    |    33 %    |    59 %     |
|    1  |  back24:1  |    58 C    |    59 C    |   100 %    |    35 %    |    59 %     |
|    2  |  back24:2  |    57 C    |    63 C    |   100 %    |    37 %    |    59 %     |
|    3  |  back24:3  |    60 C    |    60 C    |   100 %    |    38 %    |    59 %     |
|    4  |  back24:4  |    49 C    |    57 C    |   100 %    |    24 %    |    59 %     |
|    5  |  back24:5  |    58 C    |    61 C    |   100 %    |    24 %    |    59 %     |
|    6  |  back24:6  |    57 C    |    63 C    |   100 %    |    40 %    |    59 %     |
|    7  |  back24:7  |    58 C    |    62 C    |   100 %    |    39 %    |    59 %     |
|    8  |  back25:0  |    56 C    |    58 C    |   100 %    |    30 %    |    45 %     |
|    9  |  back25:1  |    52 C    |    60 C    |   100 %    |    32 %    |    45 %     |
|   10  |  back25:2  |    65 C    |    64 C    |   100 %    |    32 %    |    45 %     |
|   11  |  back25:3  |    61 C    |    63 C    |   100 %    |    32 %    |    45 %     |
|   12  |  back25:4  |    49 C    |    58 C    |   100 %    |    24 %    |    45 %     |
|   13  |  back25:5  |    54 C    |    61 C    |   100 %    |    25 %    |    45 %     |
|   14  |  back25:6  |    56 C    |    61 C    |   100 %    |    31 %    |    45 %     |
|   15  |  back25:7  |    52 C    |    64 C    |   100 %    |    37 %    |    45 %     |
|   16  |  back53:0  |    59 C    |    66 C    |   100 %    |    28 %    |    59 %     |
|   17  |  back53:1  |    57 C    |    66 C    |   100 %    |    25 %    |    59 %     |
|   18  |  back53:2  |    51 C    |    58 C    |   100 %    |    26 %    |    59 %     |
|   19  |  back53:3  |    49 C    |    59 C    |   100 %    |    29 %    |    59 %     |
|   20  |  back53:4  |    54 C    |    59 C    |   100 %    |    25 %    |    60 %     |
|   21  |  back53:5  |    47 C    |    59 C    |   100 %    |    25 %    |    59 %     |
|   22  |  back53:6  |    55 C    |    67 C    |   100 %    |    26 %    |    59 %     |
|   23  |  back53:7  |    56 C    |    64 C    |   100 %    |    24 %    |    59 %     |
|   24  |  back85:0  |    43 C    |    55 C    |   100 %    |    38 %    |    45 %     |
|   25  |  back85:1  |    38 C    |    51 C    |   100 %    |    42 %    |    45 %     |
|   26  |  back85:2  |    48 C    |    58 C    |   100 %    |    39 %    |    45 %     |
|   27  |  back85:3  |    48 C    |    59 C    |   100 %    |    36 %    |    45 %     |
|   28  |  back85:4  |    47 C    |    53 C    |   100 %    |    40 %    |    45 %     |
|   29  |  back85:5  |    43 C    |    53 C    |   100 %    |    41 %    |    45 %     |
|   30  |  back85:6  |    48 C    |    47 C    |   100 %    |    40 %    |    45 %     |
|   31  |  back85:7  |    48 C    |    48 C    |   100 %    |    40 %    |    45 %     |
+--------------------------------------------------------------------------------------+
```