[[{"l":"Moreh Documentation Hub","p":["Getting Started (HAC)","HAC 서버 접속 및 사용하기","GPU 자원 변경 (moreh-switch-model)","GPU 자원 모니터링 (moreh-smi)","Docker 이미지로 Moreh 실행하기 (moreh-docker-run)","Reference Model 학습하기","Kubernetes Cluster에서 Moreh 솔루션 사용하기","Troubleshooting","Products","Moreh Model Hub","Platform Cloud Service"]}],[{"l":"MoAI Platform Overview"},{"i":"moai-platform이란","l":"MoAI Platform이란?","p":["4차 산업혁명 시대에 접어들면서 AI 기술은 빠르게 발전하고 있습니다. 그럼에도 불구하고, 대규모 AI 모델을 개발하고 학습시키는 것은 여전히 많은 도전 과제를 안고 있습니다. 이러한 과제를 해결하기 위해 모레에서는 MoAI (Moreh AI Appliances for AI Accelerators) 플랫폼을 개발하였습니다.","MoAI 플랫폼은 수천 대의 GPU를 한번에 쉽게 제어할 수 있는 확장 가능한 AI 인프라를 제공합니다. 이를 통해 엔지니어들은 필요한 만큼의 GPU 자원을 할당받아 대규모 AI 모델을 훈련하고 서비스에 적용할 수 있습니다. 뿐만 아니라, 인프라 관리자들을 위한 직관적인 모니터링 및 관리 기능까지 갖추고 있어, 효율적인 운영이 가능합니다.","GPU 자원의 유연한 활용, 개발 및 관리의 편의성을 모두 갖춘 MoAI 플랫폼을 통해 AI 프로젝트의 성공에 한 걸음 더 가까워지게 될 것입니다."]},{"l":"MoAI Platform 핵심 기술","p":["딥러닝 모델이 진화함에 따라 파라미터가 수십억~ 수백억 단위로 확장되는 등 점점 복잡해지면서 AI 인프라에는 상당히 큰 규모의 컴퓨팅 리소스가 필요합니다. 대규모 모델을 개발시 수동 병렬 처리와 GPU 및 노드 관리를 동반하여 수많은 연산들을 최적화하는 과정이 필요하며 개발자들의 많은 노력과 시간이 많이 소요됩니다.","또한, 대규모 모델을 학습하고 추론하는 과정에서 GPU 노드 장애, 서버 온도 상승으로 인한 장애, 메모리 한계와 병목 현상 등등 이슈도 종종 발생하여 이를 해결하는 것은 매우 까다로운 작업입니다.","MoAI Platform의 GPU 가상화 기능과 자동 병렬화 기능은 앞서 언급한 한계와 어려움을 다음 기능으로 대응하여 대규모 AI 시대에 효율적인 인프라를 제공합니다.","다양한 가속기, 다중 GPU 지원","GPU 가상화","동적 GPU 할당","AI Compiler 자동 병렬화"]},{"l":"MoAI Platform 특장점"},{"i":"1-다양한-가속기-다중-gpu-지원","l":"1. 다양한 가속기, 다중 GPU 지원","p":["MoAI 플랫폼은 다양한 AI 가속기를 지원하며, GPU의 종류에 관계없이 학습과 추론 작업을 실행할 수 있습니다.","LLM 대형 언어 모델(Llama2, GPT-3) 학습 및 추론","생성형 AI 모델 학습 (LaMDA, PaLM, GPT, Text-to-Video 등)","사용자는 AMD, Intel 및 NVIDIA 외의 다른 AI 가속기와 함께 사용할 수 있으며, 이를 위해 딥러닝 개발 및 모델 학습을 위한 코드를 수정할 필요가 없습니다."]},{"l":"2. GPU 가상화","p":["MoAI 플랫폼의 가상화 기능은 수천 개의 GPU를 하나의 GPU처럼 작동할 수 있게 합니다.","모델링 및 최적화 프로세스를 간소화하여 AI 엔지니어에게 원활하고 효율적인 경험을 제공합니다.","필요에 따라 GPU 자원을 확장하거나 축소할 수 있어 서비스의 확장성을 높일 수 있습니다.","여러 GPU를 활용하는 복잡성을 추상화함으로써 딥러닝 작업에서 성능을 향상시키기 위한 리소스의 관리와 배포를 쉽게 할 수 있습니다.","GPU 인프라 관리자는 가상화된 GPU를 효율적으로 활용함으로써 하드웨어의 비용을 절감할 수 있습니다."]},{"l":"3. 동적 GPU 할당","p":["MoAI 플랫폼에서는 AI 엔지니어가 필요한 만큼의 GPU 자원으로만 딥러닝 학습 및 추론을 시작할 수 있습니다.","GPU 리소스는 연산 실행 중에만 할당되어 GPU 리소스를 효율적으로 활용할 수 있습니다. 이로 인해 소프트웨어 및 인프라 개발 비용을 줄이는 데 도움이 되며, 개발 및 배포 시간을 단축할 수 있습니다.","MoAI Platform을 사용하면 동적 할당 시스템으로 인해 AI 엔지니어가 Port 연결 및 셋업하는 과정이 생략됩니다.","일반적으로 딥러닝 개발자가 가상 GPU를 사용하기 위해서는 개발 환경 구축을 위해 PyTorch 또는 Tensorflow를 GPU 클러스터 기기의 백노드와 연결하여 각 프로세스가 다른 프로세스들과 데이터를 통신하도록 설정해야 합니다.","기존 방식의 GPU VM과 달리 GPU를 실제 사용하는 시간 동안만 분 단위 요금이 부과되는 완전한 종량제 방식으로 설계되어, 이용자의 사용 패턴에 맞추어 기존 대비 대규모의 비용 절감이 가능합니다."]},{"l":"4. AI Compiler 자동 병렬화","p":["인공지능 시대에는 대형 언어 모델(LLM) 및 대형 멀티모달 모델(LMM)과 같은 대규모 모델의 훈련 및 추론에 상당한 규모의 GPU 클러스터와 효과적인 GPU 병렬화가 필요합니다.","현재 NVIDIA와 함께 사용되는 일반적인 AI 프레임워크는 모델의 크기와 복잡성, 그리고 사용 가능한 GPU의 크기나 클러스터에 따라 AI 엔지니어가 병렬화를 수동으로 조정해야 합니다. 이 과정은 시간이 많이 소요되며 종종 몇 주가 걸립니다.","MoAI 플랫폼은 특정 AI 모델과 GPU 클러스터의 크기를 기반으로 GPU 리소스를 최적으로 활용하는 Moreh AI 컴파일러를 통해 자동 병렬화를 제공합니다.","자동 병렬화를 통해 NVIDIA와 같이 몇 주가 걸리는 AI 모델의 설정 및 배포 시간을 2~ 3일로 대폭 단축할 수 있습니다.","Copyright © 2024 Moreh Corporation"]}],[{"l":"MoAI Platform Features"},{"l":"1. 가상 AI 가속기"},{"l":"GPU 동적 할당","p":["MoAI Platform이 제공하는 가상 AI 가속기의 동적 할당 기능으로 엔지니어는 필요한 만큼의 GPU 자원으로만 딥러닝 학습할 수 있습니다. 즉 연산이 실행되는 동안에만 GPU 자원이 할당되어 합리적인 비용으로 GPU 자원을 사용할 수 있습니다.","이로 인해 소프트웨어 및 인프라 개발 비용을 줄이는 데 도움이 되며, 개발 및 배포 시간을 단축할 수 있습니다."]},{"i":"pytorchtensorflow-호환성","l":"Pytorch/Tensorflow 호환성","p":["딥러닝 모델의 발전에 따라 모델의 규모가 복잡해지고 연산량이 많아지면서 이를 학습하기 위한 파라미터도 수십억~ 수백억 단위의 규모로 증가합니다. 대규모 모델을 구현하려면 수많은 파라미터와 연산을 저장하기 위한 메모리 및 GPU 간 통신에 관련된 이슈를 해결하기 위한 작업을 해야 합니다. 하지만 이 작업은 극도로 많은 시간이 소요되며 하드웨어 구성 또는 모델 구조가 바뀔 때마다 처음부터 연산별로 최적의 구현 방식을 일일이 결정하는 것은 매우 번거로운 일입니다.","MoAI Platform은 자동 병렬화 기능 과 대형 모델 학습을 위한 컴파일링 기능 을 제공하여 연산별로 최적의 구현방식을 자동으로 수행합니다."]},{"l":"2. 자동 병렬화","p":["인공지능 시대에는 LLM(대형 언어 모델) 및 LMM(대형 멀티모달 모델)과 같은 대규모 모델의 훈련 및 추론이 상당히 큰 GPU 클러스터와 효과적인 GPU 병렬화를 필요로 합니다.","현재 NVIDIA와 함께 사용되는 대부분의 AI 프레임워크는 모델의 크기와 복잡성, 그리고 사용 가능한 GPU 크기/클러스터에 따라 AI 엔지니어가 수동으로 병렬화해야 합니다. 이 설정 프로세스는 시간이 많이 소요되며 종종 몇 주가 걸립니다.","MoAI 플랫폼은 특정 AI 모델과 GPU 클러스터의 크기를 기반으로 GPU 리소스를 최적으로 활용하는 Moreh AI 컴파일러를 통해 자동 병렬화를 제공합니다.","이는 NVIDIA와 같이 몇 주가 걸리는 AI 모델의 설정 및 배포 시간을 2~ 3일로 대폭 단축할 수 있습니다.","자동 병렬화는 MoAI Platform이 지원하는 핵심 기능 중 하나이며 모델 학습/추론 작업 시 자동으로 여러 가속기에 분배하여 병렬화합니다. 따라서 일반적으로 알려진 Data Parallelism, Model Parallelism, Pipeline Parallelism 같은 병렬화 전략들을 조합하여 최적의 데이터 연산 및 분배 방법을 알아서 결정하여 확장성을 극대화합니다."]},{"l":"Advanced Parallelism","p":["MoAI Platform의 Advanced Parallelization은 기존 최적화 과정을 자동화함으로써, 최적의 병렬화 환경 변수 조합을 신속하게 결정합니다. 즉, 대규모 모델을 훈련하는 효율적인 Pipeline Parallelism, Tensor Parallelism의 최상의 매개변수와 환경변수 조합을 찾습니다."]},{"l":"3. 직관적이고 확장가능한 관리자 툴","p":["MoAI Platform이 제공하는 관리자 툴을 사용하면 고객별로 GPU 노드 사용 현황을 직관적으로 모니터링 하기 쉽습니다. 따라서 엔드유저가 사용한 GPU 자원 및 권한을 직접 관리할 수 있습니다.","애플리케이션의 규모가 커짐에 따라 더 많은 GPU 자원을 효과적으로 관리할 수 있는 구조를 갖췄으며 발생 가능한 GPU 부족 및 온도 문제에 대해 정확한 원인을 파악하고 신속하게 대응하고 해결할 수 있습니다."]},{"l":"MoAI Platform 적용시 인프라 구조"},{"l":"학습 실행 흐름","p":["Front Node 의 VM 상에서 python train.py 와 같이 프로세스를 실행시키게 되면, VM에 설치되어 있는 Moreh 솔루션 전용 Pytorch가 Back Node 의 GPU로 연결될 수 있도록 SDAManager에게 요청이 가게 합니다.","Master Node 에는 Moreh 솔루션의 관리 모듈인 SDAManager 에서 해당 통신요청을 받게 되고, 요청 (GPU 갯수 등) 을 분석하여 비어있는 Back Node에 요청을 할당하도록 합니다.","Worker Agent 는 요청을 받아서 실제로 GPU 연산을 수행하는 Job을 각 노드들에 실행하게 됩니다. 실행된 Job은 Worker process 를 통해 실행하게 됩니다.","실행된 Worker 는 VM 의 Python process 와 InfiniBand 망을 통해서 통신을 맺게 되고 학습이 수행됩니다."]},{"l":"MoAI Platform 아키텍처"},{"l":"노드 구성","p":["크게 3가지의 노드 그룹으로 구성되어 있습니다.","Master Node: Front 와 Back 의 통신을 중개하고 Moreh 솔루션 사용 현황을 관리합니다. Front Node에서 Moreh 솔루션에 학습 요청이 있을 경우, 최초로 Master Node에서 요청을 받고 Back Node와의 통신을 중개하게 됩니다. Master Node 의 S/W 및 H/W 스택은 모두 모레에서 관리, 운영하고 있습니다.","Front Node: 유저가 접속하여 사용할 수 있는 VM을 제공하기 위한 노드그룹으로, Openstack 으로 구성하여 VM을 생성하고 있습니다. Openstack 등 Front Nodes 에 올라간 S/W stack은 락플레이스에서 운영 및 관리하고 있으며, H/W는 모레에서 운영 및 관리하고 있습니다.","Back Node: 실제 GPU 연산이 수행되는 노드 그룹으로 각 노드에는 AMD MI250 GPU 4장으로 구성되어 있습니다. Back Node의 S/W 및 H/W 스택은 모두 모레에서 관리, 운영하고 있습니다."]},{"l":"서비스 구성","p":["Back Node 는 실제 GPU 연산이 수행되는 노드들이며, 아래와 같은 2개의 서비스로 구성되어 있습니다.","Core API: SDAManager 의 핵심 모듈들이 들어있는 서비스입니다. SDAManager의 모든 기능들은 본 서비스를 통해 거쳐간다고 보시면 됩니다. Core 모듈을 호출할 수 있는 API들이 gRPC 프로토콜을 통해 제공되고 있습니다. Front Node, Back Node 를 제외한 외부에서의 호출은 불가능하도록 보안정책을 적용하고 있습니다.","DB: SDAManager 관리에 필요한 메타 데이터, 유저 데이터, GPU 사용관련 데이터 등 SDAManager 와 관련된 모든 데이터를 저장하고 있습니다.","Front Node 의 VM 상에서는 다음과 같은 서비스를 제공합니다.","get-reference-model: HAC 서비스에서는 Moreh 솔루션 상에서 동작이 검증된 Pytorch 및 Tensorflow의 Reference Model 을 완성된 코드레벨로 제공하고 있습니다. 유저는 이 툴을 활용하여 원하는 Reference Model 모델을 쉽게 VM 내에 다운받아 학습을 수행할 수 있습니다. 어떤 모델이 제공되는지는 HAC 공식 홈페이지의 Hyperscale AI Computing 모델 구성 를 참고 바랍니다.","Master Node 의 SDAManager는 Kubernetes 환경에서 동작하며, 현재 3대의 물리서버로 고가용성을 보장하고 있습니다.","Moreh 솔루션 전용 Pytorch","moreh-docker-run: HAC 서비스에서는 Moreh 솔루션이 설치된 도커 이미지를 제공하고 있습니다. 컨테이너 내에서 학습을 수행하고 싶은 유저는 이 툴을 활용하여 쉽게 모레 도커 이미지를 다운받아 실행할 수 있습니다.","moreh-smi: GPU 연산 시 메모리 사용량, 프로세스 현황 등을 확인할 수 있습니다. (NVIDIA의 nvidia-smi 와 비슷한 툴입니다.)","moreh-switch-model: AI 가속기를 변경할 수 있습니다. GPU의 사이즈를 변경하고 싶을 때 사용하며, 미리 원하는 AI 가속기로 변경을 하고 프로세스를 실행하여야, 해당 프로세스가 변경된 AI 가속기, 즉 변경된 GPU 사이즈에서 실행됩니다.","moreh-toolkit","Schduler: Front Node에서 학습 요청이 있을 경우, 어떤 Back Node 로 얼마나 많은 자원을 할당해야 할지를 관리하는 스케줄러 서비스입니다.","update-moreh: Moreh 솔루션을 최신버전을 업데이트 하거나 롤백할 수 있습니다.","Worker Agent: SDAManager로부터 GPU 할당 및 해제 요청을 받을 경우 해당 Back Node의 Worker 프로세스를 실행 및 중지 등을 관리합니다. 또한 해당 노드의 S/W 또는 H/W 장애를 감지하는 역할을 하기도 합니다.","Worker: GPU 연산을 수행하는 프로세스입니다. 요청이 없을 경우에는 프로세스가 실행되어 있지 않다가, Worker Agent가 요청을 받을 경우 이 Worker 프로세스를 실행합니다. 학습이 종료되면 Worker 프로세스도 함께 종료됩니다.","현재 Pytorch는 1.13.1, 1.10.0, 1.7.1 버전을, Tensorflow는 2.9 버전을 제공하고 있습니다. Moreh 솔루션 전용 Pytorch/Tensorflow는 공개 패키지와 내용이 거의 동일하나, GPU 연산을 수행하게 되면, 해당 VM 내에 GPU 디바이스를 찾는 것이 아닌, Back Node 의 GPU에서 디바이스를 할당받고 연산이 수행될 수 있도록 일부 코드를 수정한 버전입니다. 기능 및 성능 면에서는 공개 패키지와 동일하다고 보시면 됩니다."]}],[{"l":"MoAI 사용하기"},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Getting Started","p":["이 매뉴얼은 개발자가 터미널에 접속해서 MoAI 플랫폼을 이용하는 Quickstart 가이드를 제공합니다."]},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 해당 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Docker 이미지로 Moreh 실행하기"},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 방법"},{"l":"moreh-docker-run","p":["MoAI Platform은 도커 컨테이너 안에서 AI 가속기를 사용하는 PyTorch 프로그램을 실행할 수 있도록 전용 도커 이미지를 제공하고 있습니다. VM에서 다음의 명령어들을 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","moreh-docker-run 은 도커의 권한이 필요한 실행 스크립트입니다. 따라서 아래와 같은 명령어로 사전에 docker 권한 수정이 필요합니다. sudo chmod 666 /var/run/docker.sock","moreh-docker-run 명령어를 사용해 Moreh 솔루션이 담긴 도커 이미지를 실행합니다. 추가적으로 다른 옵션값을 안주고 실행했을 경우에는 현재까지 배포된 Moreh 솔루션 이미지 중 가장 최신 버전 도커 이미지를 실행하게 됩니다.","moreh-docker-run 명령어 뒤에 추가 옵션을 통해 도커 이미지만 다운로드 받기, 버전 확인 등을 실행할 수 있습니다.","moreh-docker-run 명령어는 Moreh 솔루션 23.11.0 버전 이후로는 기본적으로 pytorch 1.13.1 버전의 도커 이미지를 제공하고 있습니다. 23.11.0 버전 이전으로는 기본적으로 pytorch 1.7.1 버전의 도커 이미지를 제공하고 있습니다."]},{"l":"Supported Arguments","p":["pullonly (-p)","해당 옵션값을 추가로 줄경우, Moreh 솔루션 이미지를 바로 실행하지 않고 단순히 다운로드하게 됩니다.","해당 옵션값을 사용할 때는 --target 옵션값을 추가로 사용할 수 있으며, --target 옵션 값 뒤에는 아래 예시 명령어와 같이 버전을 명시해줘야 합니다. 만일 없을 경우 최신버전 이미지를 가져오게 됩니다.","version (-v)","Moreh 솔루션 도커 이미지 버전명을 보여줍니다.","—-target {VERSION}","특정 Moreh 솔루션 버전의 도커 이미지를 실행합니다. 기본값은 최신 모레 솔루션 버전이 들어가게 됩니다.","--torch {VERSION}","Moreh 솔루션 도커 이미지내에 설치된 torch 버전을 명시합니다. 기본값은 1.13.1입니다. ( Moreh솔루션 23.11.0 이후)","--tensorflow {VERSION}","Moreh 솔루션 도커 이미지 내에 설치된 Tensorflow 버전을 명시합니다. 기본값은 2.9.0입니다. 현재 Moreh 솔루션에서는 tensorflow 2.9.0 버전만 제공 중 인 점 참고부탁드립니다."]},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 시나리오","p":["VM에서 다음과 같이 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","만일, 특정 버전의 Moreh 솔루션 이미지를 실행하고 싶다면, 위 명령어 뒤에 —-target 이라는 옵션을 추가하여 원하시는 Moreh 솔루션 버전 도커 이미지를 실행하실 수 있습니다. 만일 해당 옵션 없이 moreh-docker-run 을 실행하면 현재까지 배포된 Moreh 솔루션 중 최신 버전으로 이미지를 실행하게 됩니다.","컨테이너 안에서 AI 가속기 정보를 조회하고 PyTorch 프로그램을 실행시킬 수 있습니다.","컨테이너 안에서 인식되는 AI 가속기는 VM에 할당된 AI 가속기와 동일한 것입니다. VM에서 가속기 모델을 변경하면 컨테이너 안에서도 적용되며 그 반대도 마찬가지입니다. 또한 VM에서 AI 가속기를 사용하는 동안은 컨테이너 안에서는 AI 가속기를 사용할 수 없으며 이것 역시 반대도 마찬가지입니다. 예를 들어 VM에서 AI 가속기를 사용하는 pytorch-sample.py 프로그램이 실행 중인 동안 컨테이너에서 AI 가속기를 사용하는 다른 프로그램을 실행할 경우, 아래와 같은 메시지를 출력하고 VM에서 pytorch-sample.py 프로그램이 끝날 때까지 대기하게 됩니다.","이 문서의 나머지 부분에서는 MoAI Platform를 위한 Docker 컨테이너를 실행하는 과정을(즉, moreh-docker-run 명령이 내부적으로 하는 일을) 단계별로 자세히 설명합니다.","\uD83D\uDCA1 도커를 사용하지 않고도 VM 안에서 바로 AI 가속기를 사용해 PyTorch 프로그램 실행이 가능합니다. 이 문서는 특별히 도커 기반으로 실행해야 하는 애플리케이션이 있는 분들을 대상으로 합니다."]},{"l":"도커 이미지 내려받기","p":["위와 다르게, 단순히 Moreh 솔루션 이미지만 내려받고 싶으시다면 —-pullonly (-p) 옵션을 활용하여 이미지를 내려받을수 있습니다.","해당 명령어도 위와 동일하게 만일 특정 버전의 Moreh 솔루션 이미지를 내려받고싶다면, —-target 옵션 추가로 이를 수행하실수가 있습니다. 만일 해당 옵션없이 moreh-docker-run --pullonly 을 실행하면 현재까지 배포된 Moreh 솔루션중 최신 버전으로 이미지를 실행하게 됩니다."]},{"l":"Docker Container runtime으로 컨테이너 시작","p":["moreh-docker-run 외에 다음과 같이 docker run 명령으로 동일하게 컨테이너를 실행할 수 있습니다. 이 때 다음의 옵션을 포함시켜야 합니다.","v /etc/moreh:/etc/moreh"]}],[{"i":"gpu-자원-모니터링-moreh-smi","l":"GPU 자원 모니터링 (moreh-smi)","p":["$ MOREH_VISIBLE_DEVICE=0 python train_your_script_00.py$ MOREH_VISIBLE_DEVICE=1 python train_your_script_01.py","1~ 5번 명령어를 통해 단일 SDA 디바이스를 설정하고 모니터링 할 수 있으며, 6~8번 명령어를 통해 다중 SDA 디바이스를 설정할 수 있습니다.","AI 가속기 디바이스, 즉 Software-Defined Accelerator(이하 SDA)는 아래 8가지 명령어로 사용할 수 있습니다.","Device ID 0번 SDA → train_your_script_00.py 을 실행함과 동시에","Device ID 1번 SDA → train_your_script_01.py 을 실행할 수 있습니다.","MoAI Platform의 다중 SDA는 Token 1개당 1개 이상의 디바이스 종류를 생성/삭제할 수 있는 기능을 지원합니다. 하나 이상의 디바이스가 지원되는 것과 동시에 사용자 친화적으로 인터페이스가 구성되어 하나의 Token으로 여러 개의 디바이스의 프로세스를 유연하게 실행할 수 있습니다.","moreh-smi --reset- SDA 프로세스 종료하기","moreh-smi -i- SDA 활용 상태 모니터링하기","moreh-smi -p- SDA 상세 하드웨어 상태 모니터링하기","moreh-smi -t- SDA 토큰 정보 확인하기","moreh-smi device --add- SDA 생성하기","moreh-smi device --rm- SDA 삭제하기","moreh-smi device --switch- SDA 디바이스 기본값 변경하기","moreh-switch-model- SDA 변경하기","SDA 복제 기능( Duplicable) 설정을 통해 최대 횟수만큼 병렬 학습을 진행할 수 있으나 해당 기능은 관리자를 통해 설정 요청 부탁드립니다.","VM 1개를 여러 명이 동시에 공유해야 할 경우, VM의 자원을 효율적으로 활용할 수 있습니다.","각 명령어의 다양한 옵션에 대해서 더 자세히 알고 싶다면 moreh-smi --help 로 확인 가능합니다.","단일 SDA를 사용한다면 moreh-switch-model 명령어를 통해 하나의 GPU 자원의 종류를 선택할 수 있습니다. 반면에 다중 SDA를 사용한다면, 하나의 VM에서 여러 개의 SDA 디바이스를 동시에 선택하고 실행할 수 있습니다.","단일 SDA와 다중 SDA의 차이점","실행 프로세스","예를 들어 아래와 같이 moreh-smi device --add {model_id} 로 SDA를 추가하여 총 2개의 SDA가 설정되었다면 1개의 Token에 대해 VM 한 곳에서 동시에 2개의 프로세스를 실행할 수 있습니다.","위 명령어로 여러 개의 GPU 묶음을 할당하여 병렬 학습을 진행할 수 있습니다.","위와 같은 상황에서 병렬 실행을 통해 동시에 GPU 자원을 사용할 수 있습니다.","이제 개별 명령어에 대해 설명 드리겠습니다.","하나의 VM에서 여러 개의 SDA 디바이스를 동시에 실행함으로써 아래와 같은 다양한 장점을 얻을 수 있습니다.","학습에 사용할 하이퍼파라미터를 탐색하기 위한 Hyperparameter Tuning 작업을 여러 번의 학습을 동시에 실행하여 최적의 설정 값을 찾을 수 있습니다."]},{"l":"1. SDA 활용 상태 모니터링하기 moreh-smi","p":["Moreh 소프트웨어 툴은 moreh-smi 명령어를 통해 현재 선택된 SDA 모델, 실행 중인 학습 프로세스, GPU Resource를 얼마나 할당받고 있는지를 확인할 수 있습니다."]},{"i":"2-sda-token-정보-확인하기-moreh-smi--p","l":"2. SDA token 정보 확인하기 moreh-smi -p","p":["moreh-smi -p 명령어로 현재 선택된 SDA 모델에 할당된 노드의 아래와 같은 정보를 확인할 수 있습니다."]},{"i":"3-sda-token-정보-확인하기-moreh-smi---token","l":"3. SDA token 정보 확인하기 moreh-smi --token","p":["Token 값은 사용자를 식별하기 위한 해시 값이며 사용자마다 고유 값을 가지고 있습니다. Token은 일반적으로 사용자의 가상 머신(VM) 안에 위치하며, 모레솔루션을 사용할 서버는 Token 값을 바탕으로 사용자를 식별하고 학습이 실행되므로, Token 없이는 GPU 연산 및 Python 애플리케이션을 실행할 수 없습니다.","moreh-smi --token 또는 moreh-smi -t 명령어로 VM에서 Token 설정 상태를 확인할 수 있습니다.","터미널에 해당 명령어를 입력하면 어떤 Token이 설정되어있는지 확인할 수 있습니다."]},{"l":"4. SDA 변경하기 moreh-switch-model","p":["moreh-switch-model 명령어를 통해 SDA 디바이스를 변경하여 가상 머신에서 사용할 GPU 리소스의 양을 조정할 수 있습니다.","moreh-switch-model 명령어를 사용하면 아래와 같은 입력창이 나타납니다.","1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “The KT AI Accelerator model is successfully switched to .” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA 모델로 변경됩니다. 여기서는 1번 Small.64GB 로 SDA 모델을 변경해보겠습니다.","변경을 계속하거나 q 또는 Q 를 통해 SDA 모델 변경을 종료할 수 있습니다."]},{"i":"5-sda-프로세스-종료하기-moreh-smi---reset","l":"5. SDA 프로세스 종료하기 moreh-smi --reset","p":["moreh-smi --reset 또는 moreh-smi -r 명령어를 통해 SDA 디바이스를 사용하고 있는 프로세스를 종료할 수 있습니다.","다음은 학습 중 종료한 예시입니다.","“Device release success.” 메시지와 함께 종료된 걸 확인할 수 있습니다.","아래와 같이 프로세스가 존재하지 않는 경우에는 “Device release failed. (Not running job.)” 메시지와 함께 실패합니다."]},{"i":"6-sda-추가하기-moreh-smi-device---add","l":"6. SDA 추가하기 moreh-smi device --add","p":["가상 머신(VM)이 생성된 직후에는 SDA는 1개까지만 기본값으로 제한되어 있습니다. 2개 이상의 SDA 사용이 필요한 경우 관리자에게 문의하여 제한값 설정을 요청 부탁드립니다.","하나의 VM 내에서는 최대 5개까지의 SDA를 생성할 수 있습니다.","Token의 제한 값이 변경된 이후 moreh-smi device --add 명령어로 SDA를 추가할 수 있습니다.","다음은 SDA를 추가하는 예제입니다.","moreh-smi device --add 커맨드를 입력하면 moreh-switch-model 과 동일한 인터페이스가 나타납니다. 1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “Create device success.” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA가 생성됩니다. 여기서는 3번 Large.256GB 로 SDA를 하나 더 생성해 보겠습니다.","moreh-smi device --add {model_id} 명령어를 통해 대화형 입력창 없이 바로 SDA를 생성할 수도 있습니다.","여기서 {model_id} 는 SDA 모델의 번호를 의미하며, Large.256GB 의 경우에는 ‘3’ 이 됩니다."]},{"i":"7-생성된-sda-디바이스-삭제하기-moreh-smi-device---rm","l":"7. 생성된 SDA 디바이스 삭제하기 moreh-smi device --rm","p":["생성된 SDA 디바이스를 삭제하려면 moreh-smi device --rm 명령어를 사용하면 됩니다.","moreh-smi device --rm {Device_ID} 명령어로 특정 Device_ID에 해당하는 SDA를 삭제해보겠습니다.","만약 help message에 device --add 와 같은 옵션의 도움말이 등장하지 않는다면 사용자 token에 대한 최대 디바이스 개수가 1로 설정된 것이므로 고객지원을 요청 부탁드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"l":"8. SDA 생성된 디바이스 기본값 변경하기","p":["moreh-smi device --switch {Device_ID} 명령어를 입력하면 이미 생성된 디바이스의 ID에 해당하는 디바이스로 변경됩니다.","moreh-smi device --switch {Device_ID} 를 통해 0번 Medium.128GB 을 기본 SDA로 변경해 보겠습니다.","생성된 SDA 모델 리스트 중 디바이스에 해당하는 정수를 입력하면 “Switch current device success.” 메시지와 함께 입력된 SDA가 기본 디바이스로 설정됩니다. 학습 프로세스 실행하면 설정한 기본 SDA 디바이스를 사용합니다.","여기서는 다시 1번 Medium.128GB 을 기본 SDA 디바이스로 변경해 보겠습니다.","이제 학습 실행 시 기본 값으로 1번 디바이스를 사용하게 됩니다."]}],[{"i":"gpu-자원-변경하기-moreh-switch-model","l":"GPU 자원 변경하기 (moreh-switch-model)","p":["VM에서 사용할 GPU의 개수를 조정할 수 있습니다. 다음 명령어(moreh-switch-model)를 통해 SDA를 변경할 수 있습니다.","현재 지원하는 SDA는 다음(Figure 1)과 같습니다. 번호로 SDA을 선택할수있고, q(또는 Q)로 대화를 종료 할 수 있습니다.","제일 작은 단위의 SDA는 Small.64GB이며 총 64GB 메모리를 가지고 있습니다. 그 이상 SDA는 Small.64GB의 배수만큼의 계산능력과 메모리를 가집니다. 예를 들어 Large.256GB는 Small.64GB에 비해 4배의 계산능력과 메모리를 가집니다."]}],[{"i":"moreh-솔루션-업데이트-하기-update-moreh","l":"Moreh 솔루션 업데이트 하기 (update-moreh)","p":["Moreh 솔루션은 주기적으로 업데이트되면서 솔루션의 전반적 성능이 개선되고 있습니다. Moreh 솔루션을 활용하는 방식에 따라 특정 버전의 Moreh 솔루션만을 사용하실 수 있지만, 가급적 최신 Moreh 솔루션을 사용하시는 것을 권장하고 있습니다. Moreh 솔루션을 업데이트하시면 사용하시는 환경의 Deep learning framework(PyTorch, TensorFlow) 및 Moreh driver 등의 필수 패키지들이 업데이트됩니다.","Moreh 솔루션은 다음 명령어를 통해 업데이트하실 수 있습니다.","기본적으로 위 명령어 실행 시 현재까지 배포된 버전 중 최신 버전으로 업데이트를 진행합니다.","-target","Moreh 솔루션을 특정 버전으로 다운(업)그레이드를 할 수 있는 옵션입니다. --target 옵션 뒤에는 특정 버전을 아래와 같이 기입해주시면 됩니다."]},{"l":"Deep Learning Framework 버전 변경하기","p":["Moreh 솔루션은 Pytorch 1.7.1 버전뿐만이 아닌 Pytorch 1.10.0, 1.13.1 버전과 Tensorflow 2.9.0 버전에 대해서도 제공하고 있습니다.","다른 버전의 Framework 설치를 위한 옵션은 다음과 같습니다."]},{"l":"PyTorch 버전 변경하기"},{"l":"TensorFlow 버전 변경하기","p":["\uD83D\uDCA1 Tensorflow와 Pytorch 1.10.0 혹은 1.13.1 버전은 동시에 설치를 할 수 없습니다."]}],[{"l":"K8S Cluster에서 Moreh 솔루션 사용하기"},{"l":"K8S Cluster에 접근하기 위한 서버 접속","p":["K8S Cluster를 사용하기 위해 moreh-k8s-master-vm01 서버로 접속해야합니다.","관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","관리자가 해당 VM 접속정보를 이용자에게 제공하였다고 가정해보겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"Pod을 띄우기 위한 Manifest 파일 작성","p":["$ kubectl apply -f {파일 경로}","$ kubectl exec -it {pod 이름} -n {namespace} -c {container 이름} -- /bin/bash","$ kubectl get pods -n {metadata.namespace}","apply: 해당 액션으로 쿠버네티스 리소스를 생성/수정","f: 파일 경로","K8S 클러스터 안에서 pod을 띄우기 위해 다음과 같이 작성합니다.","K8S 클러스터에 pod을 생성하기 위해 다음의 명령어로 위에서 작성한 manifest 파일을 적용합니다.","K8S 클러스터에 해당 pod이 생성되었는지 다음의 명령어로 확인합니다.","Manifest 파일은 쿠버네티스 오브젝트를 관리하기 위한 선언적 specification을 포함하는 YAML 파일입니다.","metadata.name: pod의 이름","spec.template.spec.containers[0].env[0].value: 사용할 토큰","spec.template.spec.containers[0].image: Moreh 솔루션의 도커 이미지","spec.template.spec.containers[0].name: container의 이름","먼저 모레 솔루션이 작동하는지 여부를 moreh toolkit을 활용해 확인해봅니다.","사용자가 작성해야 할 주요 key는 다음과 같습니다.","생성한 pod에 다음의 명령어로 접속합니다."]},{"l":"Moreh Toolkit 사용","p":["moreh-smi","moreh-switch-model","만약 moreh tools를 실행했을 때 다음과 같이 ‘moreh::InvalidToken’ 에러가 발생한 경우 토큰 설정을 해주어야 합니다.","컨테이너 내부에서 /etc/moreh/token 에 할당받은 토큰을 입력하면 위의 문제가 해결됩니다."]},{"l":"Duplicable SDA 설정","p":["추론 시스템을 구축하는 경우, 하나의 SDA에서 여러 프로세스를 만들 필요가 있을 수 있습니다. 이러한 경우 duplicable SDA 설정을 통해 하나의 SDA에서 다수의 GPU 활용 프로그램을 실행할 수 있습니다.","Duplicable SDA는 moreh-smclient 를 통해 설정할 수 있습니다."]},{"l":"PyTorch 학습","p":["샘플 코드인 pytorch-sample.py를 사용해 학습을 진행하면 다음과 같은 결과를 얻을 수 있습니다."]},{"l":"사용 완료한 Pod 제거","p":["pod을 제거하기 위해서는 먼저 deployment를 삭제해야합니다.","$ kubectl delete pod {pod 이름} -n {namespace} 로 pod을 삭제하면 deployment 컨트롤러가 새 pod을 생성하여 복제본 수를 유지하려고 하기 때문입니다.","다음의 명령어로 deployment를 삭제합니다.","$ kubectl delete deployment {deployment 이름} -n {namespace}","그 후 pod을 제거합니다.","$ kubectl delete pod {pod 이름} -n {namespace}","pod이 삭제되었는지 확인합니다.","$ kubectl get pods -n {namespace}"]}],[{"l":"Large Model 학습하기","p":["LM(Large Model) 이란?","Moreh framework 에서 학습, 추론이 가능한 대형 추론 모델을 의미합니다. 정기적으로 프레임워크와 함께 배포되며 Moreh 솔루션에서 딥러닝 학습에 필수적인 단계들을 수행할 수 있는 대형 언어 및 추론 모델을 다운로드할 수 있습니다. 따라서 사용자는 Large Model을 활용하여 직접 코딩하지 않아도 바로 학습, 추론을 수행할 수 있습니다.","Moreh 솔루션에서 지원하는 AI 프레임워크인 PyTorch와 TensorFlow, 그리고 학습 실행 방법을 설명 드리겠습니다."]},{"l":"PyTorch"},{"l":"1. Large Language Model 코드 다운로드","p":["아래 간단한 명령어 한 줄로 다양한 Large Model 코드를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 RM Code 설치 파일을 다운로드하고 실행하여 학습에 필요한 파일을 설치합니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다.","get-reference-model 명령어는 sudo 없이 사용하시길 권장드립니다. sudo 명령어가 포함될 경우, 실행 시 아래와 같은 에러가 발생할 수 있습니다."]},{"l":"2. Large Language Model 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"l":"3. 제공되는 모든 Large Model 목록 확인하기","p":["현재 어떤 모델 코드들이 제공되는지 궁금하시다면 —-show(또는 -s) 옵션을 이용하여 확인할 수 있습니다. 가장 범용적으로 쓰이는 딥러닝 모델과 Moreh 솔루션을 이용한 딥러닝 학습 모범 사례로 쓰일만한 안전한 모델들이 목록에 나타납니다."]},{"l":"4. Large Model 설치 파일 설정하기","p":["모델 설치 파일 (.sh) 에 대해서 수정 사항이 필요할 경우엔 아래와 같이 --download-only 옵션을 추가하여 모델 설치 파일만 다운로드 하실수도 있습니다. 해당 옵션을 추가하고 실행하면 실행 경로에 install_MODEL_NAME.sh 파일이 생성됩니다.","다음은 install_resnet.sh 파일을 다운받는 명령어 예시입니다.","모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 ResNet 모델을 설치하는 예시입니다.","—-download-only 옵션과 —-download-dir 옵션은 같이 사용하실 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 instsall_resnet.sh 파일만 다운로드하는 명령어 예시입니다."]},{"l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]},{"l":"Tensorflow"},{"l":"1. TensorFlow 가상 환경","p":["처음 VM 생성 시 기본으로 tensorflow 이름의 Tensorflow용 conda 가상환경이 존재합니다. Tensorflow conda 환경이 없는 사용자 분들은 아래와 같은 방법으로 TensorFlow를 위한 가상환경을 생성하시기 바랍니다."]},{"l":"2. Tensorflow Large Model 코드 다운로드","p":["get-reference-model 명령어 한 줄로 다양한 Large Model(이하 LM) Code를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 Large Model Code 설치 파일 및 샘플 데이터을 다운로드하게 되며, 동시에 해당 설치 파일을 실행시켜 실행환경을 세팅해줍니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다."]},{"l":"3. Large Model 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"i":"4-large-model-설치-파일-설정하기-1","l":"4. Large Model 설치 파일 설정하기","p":["모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 /data/tf-rm 경로에 ResNet 모델 파일을 다운받는 명령어 예시입니다."]},{"i":"5-모델-학습-시작하기-1","l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"i":"hyperparameter-변경하기-1","l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]}],[{"l":"Troubleshooting","p":["Moreh 솔루션 사용 시 발생할 수 있는 일반적인 오류에 대한 해결 방안을 제공합니다."]},{"i":"two-or-more-processes-cannot-use-kt-ai-accelerator-at-the-same-time","l":"Two or more processes cannot use KT AI Accelerator at the same time.","p":["SDA가 이미 사용 중인 경우, Two or more processes cannot use KT AI Accelerator at the same time. 경고 메시지가 출력될 수 있습니다. moreh-smi --reset 명령을 실행하여 강제로 SDA를 해제할 수 있습니다. 동일한 토큰 값으로 여러 개의 Pod를 띄워 SDA를 동시에 사용하려는 경우(e.g., K8s 기반 서비스) KT Cloud에 문의하여 토큰의 duplicable 설정을 받으시기 바랍니다.","moreh-smi --reset 으로 강제로 SDA 해제"]},{"i":"morehinvalidtoken","l":"moreh::InvalidToken.","p":["SDA 토큰이 적용되지 않아 발생하는 오류 메시지입니다. 환경 변수 MOREH_SDA_TOKEN 를 할당받은 토큰으로 설정한 후, 모레 솔루션을 사용하시면 해당 오류가 해결됩니다."]},{"i":"update-moreh---tensorflow-명령줄-실행-시-업데이트가-진행되지-않거나-python-패키지가-잡히지-않는-경우","l":"update-moreh --tensorflow 명령줄 실행 시 업데이트가 진행되지 않거나 Python 패키지가 잡히지 않는 경우.","p":["해당 문제는 .local 폴더와 관련된 문제일 수 있습니다. 해당 폴더 ~/.local/lib 과 ~/.local/bin 을 삭제 후 재시도해보시기 바랍니다."]},{"l":"사용자 VM에서 Python 프로세스가 종료되지 않고 남아있는 경우","p":["모델 학습을 강제 중단 혹은 종료한다면 비정상 종료된 Python 프로세스가 종료되지 않고 남아있을 수 있습니다.","pkill python 혹은 vkill {pid} 를 통해 종료하시길 바랍니다."]},{"l":"SSH 클라이언트와 통신이 끊겨 학습이 종료되는 경우","p":["보안을 위해 일정 시간 터미널에서 동작이 없다면 SSH 클라이언트와 통신이 끊기게 됩니다.","위와 같이 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"i":"2380-이전-버전을-update-moreh-명령어로-설치할-때-moreh-솔루션이-제대로-설치되지-않는-경우","l":"23.8.0 이전 버전을 update-moreh 명령어로 설치할 때 Moreh 솔루션이 제대로 설치되지 않는 경우","p":["update-moreh 명령어 외에 파이썬 패키지 관리자인 pip을 사용하여 Moreh 솔루션을 동일하게 업데이트할 수 있습니다.","update-moreh 로 솔루션 설치가 제대로 이루어지지 않는다면 다음의 pip install 을 통해 솔루션을 설치해보시기 바랍니다."]},{"l":"Moreh 솔루션 버전을 roll back하려 할 때 update-moreh가 제대로 동작하지 않는 경우","p":["동일한 버전으로 다시 Moreh 솔루션을 설치하고 싶은 경우나, 원하는 타깃 버전으로 업(다운)그레이드가 정상적으로 되지 않을 경우 -force 옵션을 통해 강제로 Moreh 솔루션의 업데이트를 진행할 수 있습니다.","하지만 가급적이면 Moreh 솔루션 사용시 -force command는 지양하고 있으니 버전이슈로 인한 에러가 발생한 경우 고객지원을 요청 바랍니다."]}],[{"l":"MoAI Platform Overview"},{"i":"moai-platform이란","l":"MoAI Platform이란?","p":["4차 산업혁명 시대에 접어들면서 AI 기술은 빠르게 발전하고 있습니다. 그럼에도 불구하고, 대규모 AI 모델을 개발하고 학습시키는 것은 여전히 많은 도전 과제를 안고 있습니다. 이러한 과제를 해결하기 위해 모레에서는 MoAI (Moreh AI Appliances for AI Accelerators) 플랫폼을 개발하였습니다.","MoAI 플랫폼은 수천 대의 GPU를 한번에 쉽게 제어할 수 있는 확장 가능한 AI 인프라를 제공합니다. 이를 통해 엔지니어들은 필요한 만큼의 GPU 자원을 할당받아 대규모 AI 모델을 훈련하고 서비스에 적용할 수 있습니다. 뿐만 아니라, 인프라 관리자들을 위한 직관적인 모니터링 및 관리 기능까지 갖추고 있어, 효율적인 운영이 가능합니다.","GPU 자원의 유연한 활용, 개발 및 관리의 편의성을 모두 갖춘 MoAI 플랫폼을 통해 AI 프로젝트의 성공에 한 걸음 더 가까워지게 될 것입니다."]},{"l":"MoAI Platform 핵심 기술","p":["딥러닝 모델이 진화함에 따라 파라미터가 수십억~ 수백억 단위로 확장되는 등 점점 복잡해지면서 AI 인프라에는 상당히 큰 규모의 컴퓨팅 리소스가 필요합니다. 대규모 모델을 개발시 수동 병렬 처리와 GPU 및 노드 관리를 동반하여 수많은 연산들을 최적화하는 과정이 필요하며 개발자들의 많은 노력과 시간이 많이 소요됩니다.","또한, 대규모 모델을 학습하고 추론하는 과정에서 GPU 노드 장애, 서버 온도 상승으로 인한 장애, 메모리 한계와 병목 현상 등등 이슈도 종종 발생하여 이를 해결하는 것은 매우 까다로운 작업입니다.","MoAI Platform의 GPU 가상화 기능과 자동 병렬화 기능은 앞서 언급한 한계와 어려움을 다음 기능으로 대응하여 대규모 AI 시대에 효율적인 인프라를 제공합니다.","다양한 가속기, 다중 GPU 지원","GPU 가상화","동적 GPU 할당","AI Compiler 자동 병렬화"]},{"l":"MoAI Platform 특장점"},{"i":"1-다양한-가속기-다중-gpu-지원","l":"1. 다양한 가속기, 다중 GPU 지원","p":["MoAI 플랫폼은 다양한 AI 가속기를 지원하며, GPU의 종류에 관계없이 학습과 추론 작업을 실행할 수 있습니다.","LLM 대형 언어 모델(Llama2, GPT-3) 학습 및 추론","생성형 AI 모델 학습 (LaMDA, PaLM, GPT, Text-to-Video 등)","사용자는 AMD, Intel 및 NVIDIA 외의 다른 AI 가속기와 함께 사용할 수 있으며, 이를 위해 딥러닝 개발 및 모델 학습을 위한 코드를 수정할 필요가 없습니다."]},{"l":"2. GPU 가상화","p":["MoAI 플랫폼의 가상화 기능은 수천 개의 GPU를 하나의 GPU처럼 작동할 수 있게 합니다.","모델링 및 최적화 프로세스를 간소화하여 AI 엔지니어에게 원활하고 효율적인 경험을 제공합니다.","필요에 따라 GPU 자원을 확장하거나 축소할 수 있어 서비스의 확장성을 높일 수 있습니다.","여러 GPU를 활용하는 복잡성을 추상화함으로써 딥러닝 작업에서 성능을 향상시키기 위한 리소스의 관리와 배포를 쉽게 할 수 있습니다.","GPU 인프라 관리자는 가상화된 GPU를 효율적으로 활용함으로써 하드웨어의 비용을 절감할 수 있습니다."]},{"l":"3. 동적 GPU 할당","p":["MoAI 플랫폼에서는 AI 엔지니어가 필요한 만큼의 GPU 자원으로만 딥러닝 학습 및 추론을 시작할 수 있습니다.","GPU 리소스는 연산 실행 중에만 할당되어 GPU 리소스를 효율적으로 활용할 수 있습니다. 이로 인해 소프트웨어 및 인프라 개발 비용을 줄이는 데 도움이 되며, 개발 및 배포 시간을 단축할 수 있습니다.","MoAI Platform을 사용하면 동적 할당 시스템으로 인해 AI 엔지니어가 Port 연결 및 셋업하는 과정이 생략됩니다.","일반적으로 딥러닝 개발자가 가상 GPU를 사용하기 위해서는 개발 환경 구축을 위해 PyTorch 또는 Tensorflow를 GPU 클러스터 기기의 백노드와 연결하여 각 프로세스가 다른 프로세스들과 데이터를 통신하도록 설정해야 합니다.","기존 방식의 GPU VM과 달리 GPU를 실제 사용하는 시간 동안만 분 단위 요금이 부과되는 완전한 종량제 방식으로 설계되어, 이용자의 사용 패턴에 맞추어 기존 대비 대규모의 비용 절감이 가능합니다."]},{"l":"4. AI Compiler 자동 병렬화","p":["인공지능 시대에는 대형 언어 모델(LLM) 및 대형 멀티모달 모델(LMM)과 같은 대규모 모델의 훈련 및 추론에 상당한 규모의 GPU 클러스터와 효과적인 GPU 병렬화가 필요합니다.","현재 NVIDIA와 함께 사용되는 일반적인 AI 프레임워크는 모델의 크기와 복잡성, 그리고 사용 가능한 GPU의 크기나 클러스터에 따라 AI 엔지니어가 병렬화를 수동으로 조정해야 합니다. 이 과정은 시간이 많이 소요되며 종종 몇 주가 걸립니다.","MoAI 플랫폼은 특정 AI 모델과 GPU 클러스터의 크기를 기반으로 GPU 리소스를 최적으로 활용하는 Moreh AI 컴파일러를 통해 자동 병렬화를 제공합니다.","자동 병렬화를 통해 NVIDIA와 같이 몇 주가 걸리는 AI 모델의 설정 및 배포 시간을 2~ 3일로 대폭 단축할 수 있습니다.","Copyright © 2024 Moreh Corporation"]}]]