[[{"l":"Moreh Documentation Hub","p":["Getting Started (HAC)","HAC 서버 접속 및 사용하기","GPU 자원 변경 (moreh-switch-model)","GPU 자원 모니터링 (moreh-smi)","Docker 이미지로 Moreh 실행하기 (moreh-docker-run)","Reference Model 학습하기","Kubernetes Cluster에서 Moreh 솔루션 사용하기","Troubleshooting","Products","Moreh Model Hub","Platform Cloud Service"]}],[{"l":"Llama2 Fine-tuning","p":["이 튜토리얼은 MoAI Platform에서 오픈 소스 Llama2 13B 모델을 fine-tuning하는 예시를 소개합니다. 튜토리얼을 통해 MoAI Platform으로 AMD GPU 클러스터를 사용하는 방법을 익히고 성능 및 자동 병렬화의 이점을 확인할 수 있습니다."]},{"l":"개요","p":["Llama2 모델은 2023년 7월에 Meta 가 공개한 Decoder-only Transformer 기반 오픈 소스 모델입니다. 기존 Llama 모델의 구조를 따르지만 40% 더 많은 데이터로 학습시켜 더 다양하고 복잡한 정보를 이해할 수 있습니다.","Llama2는 특히 언어 이해 및 생성 작업에 있어서 뛰어난 성능을 보이며, 다양한 자연어 처리 태스크에서 SOTA 성능을 달성하였습니다. 이 모델은 다국어 지원이 가능하여 전 세계 다양한 언어의 텍스트를 처리할 수 있으며, 공개적으로 접근 가능하여 연구 및 개발 목적으로 널리 사용될 수 있습니다","이 튜토리얼에서는 MoAI Platform에서 요약(summarize) 태스크에 대해 CNN Daily Mail 데이터셋을 활용해 Llama2 모델을 fine-tuning 해보겠습니다."]},{"l":"시작하기 전에","p":["MoAI Platform 상의 컨테이너 혹은 가상 머신을 인프라 제공자로부터 발급받고, 여기에 SSH로 접속하는 방법을 안내 받으시기 바랍니다. 예를 들어 MoAI Platform 기반으로 운영되는 다음 퍼블릭 클라우드 서비스를 신청하여 사용할 수 있습니다.","KT Cloud의 Hyperscale AI Computing ( https://cloud.kt.com/solution/hyperscaleAiComputing/)","혹은 일시적으로 체험판 컨테이너 및 GPU 자원을 할당 받기를 원하시는 분은 Moreh에 문의하시기 바랍니다.","(Moreh 연락처 정보 추가 예정)","SSH로 접속한 다음 moreh-smi 명령을 실행하여 MoAI Accelerator가 잘 표시되는지 확인하시기 바랍니다. 디바이스 이름은 시스템마다 다르게 설정되어 있을 수 있습니다. 만약 이 과정에 문제가 있다면 인프라 제공자에게 문의하시거나 (troubleshooting 문서 추가 예정) 문서의 가이드를 참고하시기 바랍니다."]},{"l":"MoAI Accelerator 확인","p":["이 튜토리얼에서 안내할 Llama2 모델과 같은 sLLM을 학습하기 위해서는 적절한 크기의 MoAI Accelerator를 선택해야 합니다. 먼저 moreh-smi 명령어를 이용해 현재 사용중인 MoAI Accelerator를 확인합니다.","수행할 학습에 필요한 구체적인 MoAI Accelerator 설정에 대한 설명은 “3. 학습 실행하기”에서 제공하겠습니다."]}],[{"l":"1. Fine-tuning 준비하기","p":["MoAI Platform에서 PyTorch 스크립트 실행 환경을 준비하는 것은 일반적인 GPU 서버에서와 크게 다르지 않습니다."]},{"l":"PyTorch 설치 여부 확인하기","p":["SSH로 컨테이너에 접속한 다음 아래와 같이 실행하여 현재 conda 환경에 PyTorch가 설치되어 있는지 확인합니다.","버전명에는 PyTorch 버전과 이를 실행시키기 위한 MoAI 버전이 함께 표시되어 있습니다. 위 예시의 경우 PyTorch 1.13.1+cu116 버전을 실행하는 MoAI의 24.2.0 버전이 설치되어 있음을 의미합니다.","만약 conda: command not found 메시지가 표시되거나, torch 패키지가 리스트되지 않거나, 혹은 torch 패키지가 존재하더라도 버전명에 “moreh”가 포함되지 않은 경우 (Prepare Fine-tuning on MoAI Platform) 문서에 따라 conda 환경을 생성하십시오."]},{"l":"PyTorch 동작 여부 확인하기","p":["다음과 같이 실행하여 torch 패키지가 정상적으로 import되고 MoAI Accelerator가 인식되는지 확인합니다. 만약 이 과정에 문제가 생긴다면 (troubleshooting 문서 추가 예정) 문서에 따라 조치하십시오."]},{"l":"필요 Python 패키지 설치","p":["다음과 같이 실행하여 스크립트 실행에 필요한 서드 파티 Python 패키지들을 미리 설치합니다."]},{"l":"학습 스크립트 다운로드","p":["다음과 같이 실행하여 GitHub 레포지토리에서 학습을 위한 PyTorch 스크립트를 다운로드합니다. 본 튜토리얼에서는 tutorial 디렉토리 안에 있는 train_llama2.py 스크립트를 사용할 것입니다."]},{"l":"학습 모델 및 토크나이저 다운로드","p":["Hugging Face를 이용해 Llama2-13b-hf 모델의 체크포인트와 토크나이저를 다운로드 받습니다. 이때 Llama2 모델은 커뮤니티 라이센스 동의와 Hugging Face 토큰 정보가 필요합니다. 또한 Llama2 13B 모델의 경우 체크포인트 용량이 약 49GB이기 때문에 체크포인트를 위한 50GB 스토리지 여유가 권장됩니다.","먼저 다음 사이트에서 필요한 정보를 입력한 후 라이센스 동의를 진행합니다.","meta-llama/Llama-2-13b-hf · Hugging Face","동의서 제출 후 페이지의 상태가 다음과 같이 변경된 것을 확인합니다.","Untitled","상태 변경이 되었다면, 다음과 같이 tutorial 디렉토리 안의 download_llama2_13b.py 스크립트를 이용해 모델 체크포인트와 토크나이저를 ./llama-2-13b-hf 디렉토리에 다운로드 받을 수 있습니다.","user-token 은 사용자의 Hugging Face 토큰으로 치환합니다.","모델 체크포인트와 토크나이저가 다운로드 받아졌는지 확인합니다."]},{"l":"학습 데이터 다운로드","p":["학습 데이터를 다운로드 받기 위해 dataset 디렉토리 안에 있는 prepare_llama2_dataset.py 스크립트를 사용하겠습니다. 코드를 실행하면 cnn_dailymail 데이터를 다운로드 받고 학습에 사용할 수 있도록 전처리를 진행하여 llama2_dataset.pt 파일로 저장합니다.","저장된 데이터셋은 코드상에서 다음과 같이 로드하여 사용할 수 있습니다."]}],[{"l":"2. Moreh의 학습 코드 톺아보기","p":["학습 데이터를 모두 준비하셨다면 다음으로는 실제 fine-tuning 과정을 실행할 train_llama2.py 스크립트의 내용에 대해 살펴 보겠습니다. 이 스크립트는 통상적인 PyTorch 코드로서 Hugging Face Transformers 라이브러리에 있는 Llama2 13B 모델 구현을 기반으로 fine tuning 작업을 실행합니다.","우선 제공된 스크립트를 그대로 사용하여 튜토리얼을 끝까지 진행해 보시기를 권장합니다. 이후 스크립트를 원하는 대로 수정하셔서 Llama2 13B 모델을 다른 방식으로 fine-tuning하는 것도 얼마든지 가능합니다. MoAI Platform은 PyTorch와의 완전한 호환성을 제공하기 때문입니다. 필요하시다면 Moreh에서 제공하는 MoAI Platform 응용 가이드( LLM Fine-tuning 파라미터 가이드)를 참고하십시오."]},{"l":"Training Code","p":["모든 코드는 일반적인 pytorch 사용 경험과 완벽하게 동일합니다.","먼저, transformers 라이브러리에서 필요한 모듈을 불러옵니다.","앞서 다운로드 받았던 모델 체크포인트와 토크나이저를 불러옵니다.","Fine tuning 준비하기 단계에서 저장한 전처리된 데이터셋을 불러와 데이터로더를 정의합니다.","이후 학습도 일반적인 Pytorch를 사용하여 모델 학습과 동일하게 진행됩니다.","위와 같이 MoAI Platform에서는 기존 pytorch 코드와 동일한 방식으로 작성하실 수 있습니다."]},{"l":"About Advanced Parallelism","p":["본 튜토리얼에 사용되는 학습 스크립트에서는 아래와 같은 코드가 추가로 한 줄 존재합니다. 이는 MoAI Platform에서 제공하는 최고의 병렬화 기능을 수행하는 코드입니다.","본 튜토리얼에서 사용하는 Llama2 13B와 같은 거대한 언어 모델의 경우 필연적으로 여러 개의 GPU를 사용하여 학습시켜야만 합니다. 이 경우 MoAI Platform이 아닌 다른 프레임워크를 사용할 경우, Data Parallel, Pipeline Parallel, Tensor Parallel과 같은 병렬화 기법을 도입하여 학습을 수행해야 합니다.","예를 들어, 사용자가 일반적인 pytorch 코드에서 DDP를 적용하고 싶다면, 다음과 같은 코드 스니펫이 추가되어야 합니다. ( https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)","이와 같은 기본적인 세팅 이외에도 유저는 학습 스크립트 작성 과정에서 multi processing 환경에서의 Python 코드의 동작에 대해 이해하고 있어야 하며, 특히 multi node 세팅에서는 학습에 사용되는 노드들에 대한 환경 구성 작업이 추가적으로 들어가야 합니다. 게다가 모델의 종류, 크기, 데이터셋 등을 고려한 최적의 병렬화 방법을 찾기 위해서는 매우 많은 시간이 소요됩니다.","반면, MoAI Platform의 AP기능은 유저가 직접 이러한 추가적인 병렬화 기법을 적용할 필요 없이, 단지 학습 스크립트에 다음과 같은 코드 한 줄을 추가하는 것 만으로도 최적화된 병렬화 학습을 진행할 수 있습니다.","이렇듯 다른 프레임워크에서는 경험할 수 없는 병렬화의 최적화 및 자동화 기능인 MoAI Platform만의 Advanced Parallelization(AP)을 통해 최적의 분산 병렬처리 를 경험해보시기 바랍니다. AP기능을 이용하면 일반적으로 대규모 모델 훈련시 필요한 Pipeline Parallelism, Tensor Parallelism의 최적 매개변수와 환경변수 조합을 아주 간단한 코드 한 줄 을 통해 확보할 수 있습니다."]}],[{"l":"3. 학습 실행하기","p":["이제 실제로 fine tuning을 실행해 보겠습니다."]},{"l":"가속기 Flavor 설정","p":["(모든 문서에 추가될 그림 생성 예정)","4xLarge.2048GB 로 잘 변경된 것을 확인할 수 있습니다.","4xLarge.2048GB 사용을 위해 8 을 입력합니다.","AMD MI210 GPU 32개 사용","AMD MI250 GPU 16개 사용","AMD MI300X GPU 8개 사용","KT Cloud의 Hyperscale AI Computing 사용 시: “4xLarge.2048GB” 선택","KT Hyperscale AI Computing (HAC) 서비스 가속기 모델 정보 문서를 참고하십시오.","LLM Fine-tuning 파라미터 가이드","MoAI Platform에서는 사용자에게 물리 GPU가 노출되지 않습니다. 대신 PyTorch에서 사용 가능한 가상의 MoAI Accelerator가 제공됩니다. 가속기의 flavor를 설정함으로써 실제로 PyTorch에서 물리 GPU를 얼마나 활용할지를 결정할 수 있습니다. 선택한 가속기 Flavor에 따라 학습 총 시간 및 gpu 사용 비용이 달라지므로 사용자의 학습 상황에 따른 판단이 필요합니다. 사용자의 학습 목표에 맞는 가속기 Flavor를 선택하기 위해 다음 문서를 참고하세요.","moreh-switch-model 툴을 사용하여 현재 시스템에서 사용 가능한 가속기 flavor 리스트를 확인할 수 있습니다. 원활한 모델 학습을 위해 moreh-switch-model 명령어를 이용해 더 큰 메모리의 MoAI Accelerator로 변경할 수 있습니다.","Moreh의 체험판 컨테이너 사용 시: “4xlarge” 선택","q 를 입력해 변경을 완료합니다.","따라서 처음 설정되어 있던 “xLarge.512GB” flavor를 “4xLarge.2048GB”로 전환한 다음 moreh-smi 명령을 사용하여 정상적으로 반영되었는지 확인하겠습니다.","먼저 moreh-smi 명령어를 이용해 현재 사용중인 MoAI Accelerator를 확인합니다.","변경 사항이 잘 반영되었는지 확인하기 위해 다시 moreh-smi 명령어를 이용해 현재 사용중인 MoAI Accelerator를 확인합니다.","앞서 ‘ Llama2 Fine-tuning‘ 문서에서 MoAI Accelerator를 확인했던 것을 기억하시나요? 이제 본격적인 학습 실행을 위해 필요한 가속기를 설정해보겠습니다.","여기서 번호를 입력하여 다른 flavor로 전환할 수 있습니다.","이번 튜토리얼에서는 2048GB 크기의 MoAI Accelerator를 이용하겠습니다.","튜토리얼을 계속 진행하기 위해 인프라 제공자에게 각 flavor에 대응되는 GPU 종류 및 개수를 문의하십시오. 다음 중 하나에 해당하는 flavor를 선택하여 계속 진행하십시오.","현재 사용중인 MoAI Accelerator의 메모리 크기는 512GB입니다."]},{"l":"학습 실행","p":["주어진 train_llama2.py 스크립트를 실행합니다.","학습이 정상적으로 진행된다면 다음과 같은 로그가 출력 될 것입니다. 로그를 통해 최적의 병렬화 설정을 찾는 Advanced Parallelism 기능이 정상 동작하는 것을 확인할 수 있습니다. 앞서 살펴 본 PyTorch 스크립트 상에서는 AP 코드 한 줄을 제외한 다른 부분에서 GPU 여러 개를 동시에 사용하기 위한 처리가 전혀 없었음을 참고하십시오.","훈련 로그를 확인해보면 학습이 정상적으로 이루어지는 것을 확인할 수 있습니다.","학습 도중에 출력되는 throughput은 해당 PyTorch 스크립트를 통해 초당 몇 개의 token을 학습하고 있는지를 의미합니다.","AMD MI250 GPU 16개 사용 시: 약 35,000 tokens/sec","GPU 종류 및 개수에 따른 대략적인 학습 소요 시간은 다음과 같습니다.","AMD MI250 GPU 16개 사용 시: 약 10시간"]},{"l":"학습 중에 가속기 상태 확인","p":["학습 도중에 터미널을 하나 더 띄워서 컨테이너에 접속한 후 moreh-smi 명령을 실행하시면 다음과 같이 MoAI Accelerator의 메모리를 점유하며 학습 스크립트가 실행되는 것을 확인하실 수 있습니다. 실행 로그상에서 초기화 과정이 끝나고 Step 1~ 15가 출력되는 도중에 확인해 보시기 바랍니다."]}],[{"l":"4. 학습 결과 확인하기","p":["앞 장과 같이 train_llama2.py 스크립트를 실행하면 결과 모델이 llama2_summarization 디렉토리에 저장됩니다. 이는 순수한 PyTorch 모델 파라미터 파일로 MoAI Platform이 아닌 일반 GPU 서버에서도 100% 호환됩니다.","미리 다운로드한 GitHub 레포지토리의 tutorial 디렉토리 아래에 있는 inference_llama2.py 스크립트로 학습된 모델을 테스트해 볼 수 있습니다.","테스트에는 이라크에 파병된 군인과 관련된 기사 내용이 사용되었습니다.","코드를 실행합니다.","출력값을 확인해보면 모델이 입력된 프롬프트의 내용을 적절히 요약한 것을 확인할 수 있습니다."]}],[{"l":"5. GPU 개수 변경하기","p":["앞과 동일한 fine-tuning 작업을 GPU 개수를 바꾸어 다시 실행해 보겠습니다. MoAI Platform은 GPU 자원을 단일 가속기로 추상화하여 제공하며 자동으로 병렬 처리를 수행합니다. 따라서 GPU 개수를 변경하더라도 PyTorch 스크립트는 전혀 고칠 필요가 없습니다."]},{"l":"가속기 Flavor 변경","p":["moreh-switch-model 툴을 사용하여 가속기 flavor를 전환합니다. 가속기 변경 방법은 3. 학습 실행하기 문서를 한번 더 참고해주시기 바랍니다.","인프라 제공자에게 문의하여 다음 중 하나를 선택한 다음 계속 진행하십시오. ( KT Hyperscale AI Computing (HAC) 서비스 가속기 모델 정보)","AMD MI250 GPU 32개 사용","Moreh의 체험판 컨테이너 사용 시: “8xlarge” 선택","KT Cloud의 Hyperscale AI Computing 사용 시: “8xLarge.4096GB” 선택","AMD MI210 GPU 64개 사용","AMD MI300X GPU 16개 사용"]},{"l":"학습 실행","p":["다시 train_llama2.py 스크립트를 실행합니다.","사용 가능한 GPU 메모리가 ** 2배 늘었기 때문에, 배치 사이즈 또한 기존 256 에서 512 로 변경하여 실행시켜 보겠습니다.","학습이 정상적으로 진행된다면 다음과 같은 로그가 출력될 것입니다.","앞서 GPU 개수가 절반이었을 때 실행한 결과와 비교해 동일하게 학습이 이루어지며 throughput이 향상되었음을 확인할 수 있습니다.","AMD MI250 GPU 16 → 32개 사용 시: 약 35,000 tokens/sec → 74,000 tokens/sec"]}],[{"l":"6. 마무리","p":["지금까지 MoAI Platform에서 Llama2 13B 모델을 fine-tuning하는 과정을 살펴 보았습니다. Llama 와 같은 오픈 소스 LLM은 요약, 질의 응답 등 다양한 태스크에 활용할 수 있습니다. MoAI 플랫폼을 사용한다면 여러분이 필요한 GPU 수를 코드 변경 없이 손쉽게 설정할 수 있습니다. 여러분만의 데이터로 새로운 모델을 빠르고 쉽게 개발해 보세요."]},{"l":"더 알아보기","p":["MoAI Platform의 자동병렬화 기능, Advanced Parallelization (AP)","Mistral Fine-tuning","GPT Fine-tuning (KR)","Baichuan2 Fine-tuning","Qwen Fine-tuning"]}],[{"l":"MoAI Platform Overview"},{"i":"moai-platform이란","l":"MoAI Platform이란?","p":["4차 산업혁명 시대에 접어들면서 AI 기술은 빠르게 발전하고 있습니다. 그럼에도 불구하고, 대규모 AI 모델을 개발하고 학습시키는 것은 여전히 많은 도전 과제를 안고 있습니다. 이러한 과제를 해결하기 위해 모레에서는 MoAI (Moreh AI Appliances for AI Accelerators) 플랫폼을 개발하였습니다.","MoAI 플랫폼은 수천 대의 GPU를 한번에 쉽게 제어할 수 있는 확장 가능한 AI 인프라를 제공합니다. 이를 통해 엔지니어들은 필요한 만큼의 GPU 자원을 할당받아 대규모 AI 모델을 훈련하고 서비스에 적용할 수 있습니다. 뿐만 아니라, 인프라 관리자들을 위한 직관적인 모니터링 및 관리 기능까지 갖추고 있어, 효율적인 운영이 가능합니다.","GPU 자원의 유연한 활용, 개발 및 관리의 편의성을 모두 갖춘 MoAI 플랫폼을 통해 AI 프로젝트의 성공에 한 걸음 더 가까워지게 될 것입니다."]},{"l":"MoAI Platform 핵심 기술","p":["딥러닝 모델이 진화함에 따라 파라미터가 수십억~ 수백억 단위로 확장되는 등 점점 복잡해지면서 AI 인프라에는 상당히 큰 규모의 컴퓨팅 리소스가 필요합니다. 대규모 모델을 개발시 수동 병렬 처리와 GPU 및 노드 관리를 동반하여 수많은 연산들을 최적화하는 과정이 필요하며 개발자들의 많은 노력과 시간이 많이 소요됩니다.","또한, 대규모 모델을 학습하고 추론하는 과정에서 GPU 노드 장애, 서버 온도 상승으로 인한 장애, 메모리 한계와 병목 현상 등등 이슈도 종종 발생하여 이를 해결하는 것은 매우 까다로운 작업입니다.","MoAI Platform의 GPU 가상화 기능과 자동 병렬화 기능은 앞서 언급한 한계와 어려움을 다음 기능으로 대응하여 대규모 AI 시대에 효율적인 인프라를 제공합니다.","다양한 가속기, 다중 GPU 지원","GPU 가상화","동적 GPU 할당","AI Compiler 자동 병렬화"]},{"l":"MoAI Platform 특장점"},{"i":"1-다양한-가속기-다중-gpu-지원","l":"1. 다양한 가속기, 다중 GPU 지원","p":["MoAI 플랫폼은 다양한 AI 가속기를 지원하며, GPU의 종류에 관계없이 학습과 추론 작업을 실행할 수 있습니다.","LLM 대형 언어 모델(Llama2, GPT-3) 학습 및 추론","생성형 AI 모델 학습 (LaMDA, PaLM, GPT, Text-to-Video 등)","사용자는 AMD, Intel 및 NVIDIA 외의 다른 AI 가속기와 함께 사용할 수 있으며, 이를 위해 딥러닝 개발 및 모델 학습을 위한 코드를 수정할 필요가 없습니다."]},{"l":"2. GPU 가상화","p":["MoAI 플랫폼의 가상화 기능은 수천 개의 GPU를 하나의 GPU처럼 작동할 수 있게 합니다.","모델링 및 최적화 프로세스를 간소화하여 AI 엔지니어에게 원활하고 효율적인 경험을 제공합니다.","필요에 따라 GPU 자원을 확장하거나 축소할 수 있어 서비스의 확장성을 높일 수 있습니다.","여러 GPU를 활용하는 복잡성을 추상화함으로써 딥러닝 작업에서 성능을 향상시키기 위한 리소스의 관리와 배포를 쉽게 할 수 있습니다.","GPU 인프라 관리자는 가상화된 GPU를 효율적으로 활용함으로써 하드웨어의 비용을 절감할 수 있습니다."]},{"l":"3. 동적 GPU 할당","p":["MoAI 플랫폼에서는 AI 엔지니어가 필요한 만큼의 GPU 자원으로만 딥러닝 학습 및 추론을 시작할 수 있습니다.","GPU 리소스는 연산 실행 중에만 할당되어 GPU 리소스를 효율적으로 활용할 수 있습니다. 이로 인해 소프트웨어 및 인프라 개발 비용을 줄이는 데 도움이 되며, 개발 및 배포 시간을 단축할 수 있습니다.","MoAI Platform을 사용하면 동적 할당 시스템으로 인해 AI 엔지니어가 Port 연결 및 셋업하는 과정이 생략됩니다.","일반적으로 딥러닝 개발자가 가상 GPU를 사용하기 위해서는 개발 환경 구축을 위해 PyTorch 또는 Tensorflow를 GPU 클러스터 기기의 백노드와 연결하여 각 프로세스가 다른 프로세스들과 데이터를 통신하도록 설정해야 합니다.","기존 방식의 GPU VM과 달리 GPU를 실제 사용하는 시간 동안만 분 단위 요금이 부과되는 완전한 종량제 방식으로 설계되어, 이용자의 사용 패턴에 맞추어 기존 대비 대규모의 비용 절감이 가능합니다."]},{"l":"4. AI Compiler 자동 병렬화","p":["인공지능 시대에는 대형 언어 모델(LLM) 및 대형 멀티모달 모델(LMM)과 같은 대규모 모델의 훈련 및 추론에 상당한 규모의 GPU 클러스터와 효과적인 GPU 병렬화가 필요합니다.","현재 NVIDIA와 함께 사용되는 일반적인 AI 프레임워크는 모델의 크기와 복잡성, 그리고 사용 가능한 GPU의 크기나 클러스터에 따라 AI 엔지니어가 병렬화를 수동으로 조정해야 합니다. 이 과정은 시간이 많이 소요되며 종종 몇 주가 걸립니다.","MoAI 플랫폼은 특정 AI 모델과 GPU 클러스터의 크기를 기반으로 GPU 리소스를 최적으로 활용하는 Moreh AI 컴파일러를 통해 자동 병렬화를 제공합니다.","자동 병렬화를 통해 NVIDIA와 같이 몇 주가 걸리는 AI 모델의 설정 및 배포 시간을 2~ 3일로 대폭 단축할 수 있습니다.","Copyright © 2024 Moreh Corporation"]}],[{"l":"MoAI Platform Features"},{"l":"1. 가상 AI 가속기"},{"l":"GPU 동적 할당","p":["MoAI Platform이 제공하는 가상 AI 가속기의 동적 할당 기능으로 엔지니어는 필요한 만큼의 GPU 자원으로만 딥러닝 학습할 수 있습니다. 즉 연산이 실행되는 동안에만 GPU 자원이 할당되어 합리적인 비용으로 GPU 자원을 사용할 수 있습니다.","이로 인해 소프트웨어 및 인프라 개발 비용을 줄이는 데 도움이 되며, 개발 및 배포 시간을 단축할 수 있습니다."]},{"i":"pytorchtensorflow-호환성","l":"Pytorch/Tensorflow 호환성","p":["딥러닝 모델의 발전에 따라 모델의 규모가 복잡해지고 연산량이 많아지면서 이를 학습하기 위한 파라미터도 수십억~ 수백억 단위의 규모로 증가합니다. 대규모 모델을 구현하려면 수많은 파라미터와 연산을 저장하기 위한 메모리 및 GPU 간 통신에 관련된 이슈를 해결하기 위한 작업을 해야 합니다. 하지만 이 작업은 극도로 많은 시간이 소요되며 하드웨어 구성 또는 모델 구조가 바뀔 때마다 처음부터 연산별로 최적의 구현 방식을 일일이 결정하는 것은 매우 번거로운 일입니다.","MoAI Platform은 자동 병렬화 기능 과 대형 모델 학습을 위한 컴파일링 기능 을 제공하여 연산별로 최적의 구현방식을 자동으로 수행합니다."]},{"l":"2. 자동 병렬화","p":["인공지능 시대에는 LLM(대형 언어 모델) 및 LMM(대형 멀티모달 모델)과 같은 대규모 모델의 훈련 및 추론이 상당히 큰 GPU 클러스터와 효과적인 GPU 병렬화를 필요로 합니다.","현재 NVIDIA와 함께 사용되는 대부분의 AI 프레임워크는 모델의 크기와 복잡성, 그리고 사용 가능한 GPU 크기/클러스터에 따라 AI 엔지니어가 수동으로 병렬화해야 합니다. 이 설정 프로세스는 시간이 많이 소요되며 종종 몇 주가 걸립니다.","MoAI 플랫폼은 특정 AI 모델과 GPU 클러스터의 크기를 기반으로 GPU 리소스를 최적으로 활용하는 Moreh AI 컴파일러를 통해 자동 병렬화를 제공합니다.","이는 NVIDIA와 같이 몇 주가 걸리는 AI 모델의 설정 및 배포 시간을 2~ 3일로 대폭 단축할 수 있습니다.","자동 병렬화는 MoAI Platform이 지원하는 핵심 기능 중 하나이며 모델 학습/추론 작업 시 자동으로 여러 가속기에 분배하여 병렬화합니다. 따라서 일반적으로 알려진 Data Parallelism, Model Parallelism, Pipeline Parallelism 같은 병렬화 전략들을 조합하여 최적의 데이터 연산 및 분배 방법을 알아서 결정하여 확장성을 극대화합니다."]},{"l":"Advanced Parallelism","p":["MoAI Platform의 Advanced Parallelization은 기존 최적화 과정을 자동화함으로써, 최적의 병렬화 환경 변수 조합을 신속하게 결정합니다. 즉, 대규모 모델을 훈련하는 효율적인 Pipeline Parallelism, Tensor Parallelism의 최상의 매개변수와 환경변수 조합을 찾습니다."]},{"l":"3. 직관적이고 확장가능한 관리자 툴","p":["MoAI Platform이 제공하는 관리자 툴을 사용하면 고객별로 GPU 노드 사용 현황을 직관적으로 모니터링 하기 쉽습니다. 따라서 엔드유저가 사용한 GPU 자원 및 권한을 직접 관리할 수 있습니다.","애플리케이션의 규모가 커짐에 따라 더 많은 GPU 자원을 효과적으로 관리할 수 있는 구조를 갖췄으며 발생 가능한 GPU 부족 및 온도 문제에 대해 정확한 원인을 파악하고 신속하게 대응하고 해결할 수 있습니다."]},{"l":"MoAI Platform 적용시 인프라 구조"},{"l":"학습 실행 흐름","p":["Front Node 의 VM 상에서 python train.py 와 같이 프로세스를 실행시키게 되면, VM에 설치되어 있는 Moreh 솔루션 전용 Pytorch가 Back Node 의 GPU로 연결될 수 있도록 SDAManager에게 요청이 가게 합니다.","Master Node 에는 Moreh 솔루션의 관리 모듈인 SDAManager 에서 해당 통신요청을 받게 되고, 요청 (GPU 갯수 등) 을 분석하여 비어있는 Back Node에 요청을 할당하도록 합니다.","Worker Agent 는 요청을 받아서 실제로 GPU 연산을 수행하는 Job을 각 노드들에 실행하게 됩니다. 실행된 Job은 Worker process 를 통해 실행하게 됩니다.","실행된 Worker 는 VM 의 Python process 와 InfiniBand 망을 통해서 통신을 맺게 되고 학습이 수행됩니다."]},{"l":"MoAI Platform 아키텍처"},{"l":"노드 구성","p":["크게 3가지의 노드 그룹으로 구성되어 있습니다.","Master Node: Front 와 Back 의 통신을 중개하고 Moreh 솔루션 사용 현황을 관리합니다. Front Node에서 Moreh 솔루션에 학습 요청이 있을 경우, 최초로 Master Node에서 요청을 받고 Back Node와의 통신을 중개하게 됩니다. Master Node 의 S/W 및 H/W 스택은 모두 모레에서 관리, 운영하고 있습니다.","Front Node: 유저가 접속하여 사용할 수 있는 VM을 제공하기 위한 노드그룹으로, Openstack 으로 구성하여 VM을 생성하고 있습니다. Openstack 등 Front Nodes 에 올라간 S/W stack은 락플레이스에서 운영 및 관리하고 있으며, H/W는 모레에서 운영 및 관리하고 있습니다.","Back Node: 실제 GPU 연산이 수행되는 노드 그룹으로 각 노드에는 AMD MI250 GPU 4장으로 구성되어 있습니다. Back Node의 S/W 및 H/W 스택은 모두 모레에서 관리, 운영하고 있습니다."]},{"l":"서비스 구성","p":["Back Node 는 실제 GPU 연산이 수행되는 노드들이며, 아래와 같은 2개의 서비스로 구성되어 있습니다.","Core API: SDAManager 의 핵심 모듈들이 들어있는 서비스입니다. SDAManager의 모든 기능들은 본 서비스를 통해 거쳐간다고 보시면 됩니다. Core 모듈을 호출할 수 있는 API들이 gRPC 프로토콜을 통해 제공되고 있습니다. Front Node, Back Node 를 제외한 외부에서의 호출은 불가능하도록 보안정책을 적용하고 있습니다.","DB: SDAManager 관리에 필요한 메타 데이터, 유저 데이터, GPU 사용관련 데이터 등 SDAManager 와 관련된 모든 데이터를 저장하고 있습니다.","Front Node 의 VM 상에서는 다음과 같은 서비스를 제공합니다.","get-reference-model: HAC 서비스에서는 Moreh 솔루션 상에서 동작이 검증된 Pytorch 및 Tensorflow의 Reference Model 을 완성된 코드레벨로 제공하고 있습니다. 유저는 이 툴을 활용하여 원하는 Reference Model 모델을 쉽게 VM 내에 다운받아 학습을 수행할 수 있습니다. 어떤 모델이 제공되는지는 HAC 공식 홈페이지의 Hyperscale AI Computing 모델 구성 를 참고 바랍니다.","Master Node 의 SDAManager는 Kubernetes 환경에서 동작하며, 현재 3대의 물리서버로 고가용성을 보장하고 있습니다.","Moreh 솔루션 전용 Pytorch","moreh-docker-run: HAC 서비스에서는 Moreh 솔루션이 설치된 도커 이미지를 제공하고 있습니다. 컨테이너 내에서 학습을 수행하고 싶은 유저는 이 툴을 활용하여 쉽게 모레 도커 이미지를 다운받아 실행할 수 있습니다.","moreh-smi: GPU 연산 시 메모리 사용량, 프로세스 현황 등을 확인할 수 있습니다. (NVIDIA의 nvidia-smi 와 비슷한 툴입니다.)","moreh-switch-model: AI 가속기를 변경할 수 있습니다. GPU의 사이즈를 변경하고 싶을 때 사용하며, 미리 원하는 AI 가속기로 변경을 하고 프로세스를 실행하여야, 해당 프로세스가 변경된 AI 가속기, 즉 변경된 GPU 사이즈에서 실행됩니다.","moreh-toolkit","Schduler: Front Node에서 학습 요청이 있을 경우, 어떤 Back Node 로 얼마나 많은 자원을 할당해야 할지를 관리하는 스케줄러 서비스입니다.","update-moreh: Moreh 솔루션을 최신버전을 업데이트 하거나 롤백할 수 있습니다.","Worker Agent: SDAManager로부터 GPU 할당 및 해제 요청을 받을 경우 해당 Back Node의 Worker 프로세스를 실행 및 중지 등을 관리합니다. 또한 해당 노드의 S/W 또는 H/W 장애를 감지하는 역할을 하기도 합니다.","Worker: GPU 연산을 수행하는 프로세스입니다. 요청이 없을 경우에는 프로세스가 실행되어 있지 않다가, Worker Agent가 요청을 받을 경우 이 Worker 프로세스를 실행합니다. 학습이 종료되면 Worker 프로세스도 함께 종료됩니다.","현재 Pytorch는 1.13.1, 1.10.0, 1.7.1 버전을, Tensorflow는 2.9 버전을 제공하고 있습니다. Moreh 솔루션 전용 Pytorch/Tensorflow는 공개 패키지와 내용이 거의 동일하나, GPU 연산을 수행하게 되면, 해당 VM 내에 GPU 디바이스를 찾는 것이 아닌, Back Node 의 GPU에서 디바이스를 할당받고 연산이 수행될 수 있도록 일부 코드를 수정한 버전입니다. 기능 및 성능 면에서는 공개 패키지와 동일하다고 보시면 됩니다."]}],[{"l":"MoAI 사용하기"},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Getting Started","p":["이 매뉴얼은 개발자가 터미널에 접속해서 MoAI 플랫폼을 이용하는 Quickstart 가이드를 제공합니다."]},{"l":"서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 해당 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Docker 이미지로 Moreh 실행하기"},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 방법"},{"l":"moreh-docker-run","p":["MoAI Platform은 도커 컨테이너 안에서 AI 가속기를 사용하는 PyTorch 프로그램을 실행할 수 있도록 전용 도커 이미지를 제공하고 있습니다. VM에서 다음의 명령어들을 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","moreh-docker-run 은 도커의 권한이 필요한 실행 스크립트입니다. 따라서 아래와 같은 명령어로 사전에 docker 권한 수정이 필요합니다. sudo chmod 666 /var/run/docker.sock","moreh-docker-run 명령어를 사용해 Moreh 솔루션이 담긴 도커 이미지를 실행합니다. 추가적으로 다른 옵션값을 안주고 실행했을 경우에는 현재까지 배포된 Moreh 솔루션 이미지 중 가장 최신 버전 도커 이미지를 실행하게 됩니다.","moreh-docker-run 명령어 뒤에 추가 옵션을 통해 도커 이미지만 다운로드 받기, 버전 확인 등을 실행할 수 있습니다.","moreh-docker-run 명령어는 Moreh 솔루션 23.11.0 버전 이후로는 기본적으로 pytorch 1.13.1 버전의 도커 이미지를 제공하고 있습니다. 23.11.0 버전 이전으로는 기본적으로 pytorch 1.7.1 버전의 도커 이미지를 제공하고 있습니다."]},{"l":"Supported Arguments","p":["pullonly (-p)","해당 옵션값을 추가로 줄경우, Moreh 솔루션 이미지를 바로 실행하지 않고 단순히 다운로드하게 됩니다.","해당 옵션값을 사용할 때는 --target 옵션값을 추가로 사용할 수 있으며, --target 옵션 값 뒤에는 아래 예시 명령어와 같이 버전을 명시해줘야 합니다. 만일 없을 경우 최신버전 이미지를 가져오게 됩니다.","version (-v)","Moreh 솔루션 도커 이미지 버전명을 보여줍니다.","—-target {VERSION}","특정 Moreh 솔루션 버전의 도커 이미지를 실행합니다. 기본값은 최신 모레 솔루션 버전이 들어가게 됩니다.","--torch {VERSION}","Moreh 솔루션 도커 이미지내에 설치된 torch 버전을 명시합니다. 기본값은 1.13.1입니다. ( Moreh솔루션 23.11.0 이후)","--tensorflow {VERSION}","Moreh 솔루션 도커 이미지 내에 설치된 Tensorflow 버전을 명시합니다. 기본값은 2.9.0입니다. 현재 Moreh 솔루션에서는 tensorflow 2.9.0 버전만 제공 중 인 점 참고부탁드립니다."]},{"l":"MoAI Platform에서 Docker로 Moreh 솔루션을 실행하는 시나리오","p":["VM에서 다음과 같이 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","만일, 특정 버전의 Moreh 솔루션 이미지를 실행하고 싶다면, 위 명령어 뒤에 —-target 이라는 옵션을 추가하여 원하시는 Moreh 솔루션 버전 도커 이미지를 실행하실 수 있습니다. 만일 해당 옵션 없이 moreh-docker-run 을 실행하면 현재까지 배포된 Moreh 솔루션 중 최신 버전으로 이미지를 실행하게 됩니다.","컨테이너 안에서 AI 가속기 정보를 조회하고 PyTorch 프로그램을 실행시킬 수 있습니다.","컨테이너 안에서 인식되는 AI 가속기는 VM에 할당된 AI 가속기와 동일한 것입니다. VM에서 가속기 모델을 변경하면 컨테이너 안에서도 적용되며 그 반대도 마찬가지입니다. 또한 VM에서 AI 가속기를 사용하는 동안은 컨테이너 안에서는 AI 가속기를 사용할 수 없으며 이것 역시 반대도 마찬가지입니다. 예를 들어 VM에서 AI 가속기를 사용하는 pytorch-sample.py 프로그램이 실행 중인 동안 컨테이너에서 AI 가속기를 사용하는 다른 프로그램을 실행할 경우, 아래와 같은 메시지를 출력하고 VM에서 pytorch-sample.py 프로그램이 끝날 때까지 대기하게 됩니다.","이 문서의 나머지 부분에서는 MoAI Platform를 위한 Docker 컨테이너를 실행하는 과정을(즉, moreh-docker-run 명령이 내부적으로 하는 일을) 단계별로 자세히 설명합니다.","\uD83D\uDCA1 도커를 사용하지 않고도 VM 안에서 바로 AI 가속기를 사용해 PyTorch 프로그램 실행이 가능합니다. 이 문서는 특별히 도커 기반으로 실행해야 하는 애플리케이션이 있는 분들을 대상으로 합니다."]},{"l":"도커 이미지 내려받기","p":["위와 다르게, 단순히 Moreh 솔루션 이미지만 내려받고 싶으시다면 —-pullonly (-p) 옵션을 활용하여 이미지를 내려받을수 있습니다.","해당 명령어도 위와 동일하게 만일 특정 버전의 Moreh 솔루션 이미지를 내려받고싶다면, —-target 옵션 추가로 이를 수행하실수가 있습니다. 만일 해당 옵션없이 moreh-docker-run --pullonly 을 실행하면 현재까지 배포된 Moreh 솔루션중 최신 버전으로 이미지를 실행하게 됩니다."]},{"l":"Docker Container runtime으로 컨테이너 시작","p":["moreh-docker-run 외에 다음과 같이 docker run 명령으로 동일하게 컨테이너를 실행할 수 있습니다. 이 때 다음의 옵션을 포함시켜야 합니다.","v /etc/moreh:/etc/moreh"]}],[{"i":"gpu-자원-모니터링-moreh-smi","l":"GPU 자원 모니터링 (moreh-smi)","p":["$ MOREH_VISIBLE_DEVICE=0 python train_your_script_00.py$ MOREH_VISIBLE_DEVICE=1 python train_your_script_01.py","1~ 5번 명령어를 통해 단일 SDA 디바이스를 설정하고 모니터링 할 수 있으며, 6~8번 명령어를 통해 다중 SDA 디바이스를 설정할 수 있습니다.","AI 가속기 디바이스, 즉 Software-Defined Accelerator(이하 SDA)는 아래 8가지 명령어로 사용할 수 있습니다.","Device ID 0번 SDA → train_your_script_00.py 을 실행함과 동시에","Device ID 1번 SDA → train_your_script_01.py 을 실행할 수 있습니다.","MoAI Platform의 다중 SDA는 Token 1개당 1개 이상의 디바이스 종류를 생성/삭제할 수 있는 기능을 지원합니다. 하나 이상의 디바이스가 지원되는 것과 동시에 사용자 친화적으로 인터페이스가 구성되어 하나의 Token으로 여러 개의 디바이스의 프로세스를 유연하게 실행할 수 있습니다.","moreh-smi --reset- SDA 프로세스 종료하기","moreh-smi -i- SDA 활용 상태 모니터링하기","moreh-smi -p- SDA 상세 하드웨어 상태 모니터링하기","moreh-smi -t- SDA 토큰 정보 확인하기","moreh-smi device --add- SDA 생성하기","moreh-smi device --rm- SDA 삭제하기","moreh-smi device --switch- SDA 디바이스 기본값 변경하기","moreh-switch-model- SDA 변경하기","SDA 복제 기능( Duplicable) 설정을 통해 최대 횟수만큼 병렬 학습을 진행할 수 있으나 해당 기능은 관리자를 통해 설정 요청 부탁드립니다.","VM 1개를 여러 명이 동시에 공유해야 할 경우, VM의 자원을 효율적으로 활용할 수 있습니다.","각 명령어의 다양한 옵션에 대해서 더 자세히 알고 싶다면 moreh-smi --help 로 확인 가능합니다.","단일 SDA를 사용한다면 moreh-switch-model 명령어를 통해 하나의 GPU 자원의 종류를 선택할 수 있습니다. 반면에 다중 SDA를 사용한다면, 하나의 VM에서 여러 개의 SDA 디바이스를 동시에 선택하고 실행할 수 있습니다.","단일 SDA와 다중 SDA의 차이점","실행 프로세스","예를 들어 아래와 같이 moreh-smi device --add {model_id} 로 SDA를 추가하여 총 2개의 SDA가 설정되었다면 1개의 Token에 대해 VM 한 곳에서 동시에 2개의 프로세스를 실행할 수 있습니다.","위 명령어로 여러 개의 GPU 묶음을 할당하여 병렬 학습을 진행할 수 있습니다.","위와 같은 상황에서 병렬 실행을 통해 동시에 GPU 자원을 사용할 수 있습니다.","이제 개별 명령어에 대해 설명 드리겠습니다.","하나의 VM에서 여러 개의 SDA 디바이스를 동시에 실행함으로써 아래와 같은 다양한 장점을 얻을 수 있습니다.","학습에 사용할 하이퍼파라미터를 탐색하기 위한 Hyperparameter Tuning 작업을 여러 번의 학습을 동시에 실행하여 최적의 설정 값을 찾을 수 있습니다."]},{"l":"1. SDA 활용 상태 모니터링하기 moreh-smi","p":["Moreh 소프트웨어 툴은 moreh-smi 명령어를 통해 현재 선택된 SDA 모델, 실행 중인 학습 프로세스, GPU Resource를 얼마나 할당받고 있는지를 확인할 수 있습니다."]},{"i":"2-sda-token-정보-확인하기-moreh-smi--p","l":"2. SDA token 정보 확인하기 moreh-smi -p","p":["moreh-smi -p 명령어로 현재 선택된 SDA 모델에 할당된 노드의 아래와 같은 정보를 확인할 수 있습니다."]},{"i":"3-sda-token-정보-확인하기-moreh-smi---token","l":"3. SDA token 정보 확인하기 moreh-smi --token","p":["Token 값은 사용자를 식별하기 위한 해시 값이며 사용자마다 고유 값을 가지고 있습니다. Token은 일반적으로 사용자의 가상 머신(VM) 안에 위치하며, 모레솔루션을 사용할 서버는 Token 값을 바탕으로 사용자를 식별하고 학습이 실행되므로, Token 없이는 GPU 연산 및 Python 애플리케이션을 실행할 수 없습니다.","moreh-smi --token 또는 moreh-smi -t 명령어로 VM에서 Token 설정 상태를 확인할 수 있습니다.","터미널에 해당 명령어를 입력하면 어떤 Token이 설정되어있는지 확인할 수 있습니다."]},{"l":"4. SDA 변경하기 moreh-switch-model","p":["moreh-switch-model 명령어를 통해 SDA 디바이스를 변경하여 가상 머신에서 사용할 GPU 리소스의 양을 조정할 수 있습니다.","moreh-switch-model 명령어를 사용하면 아래와 같은 입력창이 나타납니다.","1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “The KT AI Accelerator model is successfully switched to .” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA 모델로 변경됩니다. 여기서는 1번 Small.64GB 로 SDA 모델을 변경해보겠습니다.","변경을 계속하거나 q 또는 Q 를 통해 SDA 모델 변경을 종료할 수 있습니다."]},{"i":"5-sda-프로세스-종료하기-moreh-smi---reset","l":"5. SDA 프로세스 종료하기 moreh-smi --reset","p":["moreh-smi --reset 또는 moreh-smi -r 명령어를 통해 SDA 디바이스를 사용하고 있는 프로세스를 종료할 수 있습니다.","다음은 학습 중 종료한 예시입니다.","“Device release success.” 메시지와 함께 종료된 걸 확인할 수 있습니다.","아래와 같이 프로세스가 존재하지 않는 경우에는 “Device release failed. (Not running job.)” 메시지와 함께 실패합니다."]},{"i":"6-sda-추가하기-moreh-smi-device---add","l":"6. SDA 추가하기 moreh-smi device --add","p":["가상 머신(VM)이 생성된 직후에는 SDA는 1개까지만 기본값으로 제한되어 있습니다. 2개 이상의 SDA 사용이 필요한 경우 관리자에게 문의하여 제한값 설정을 요청 부탁드립니다.","하나의 VM 내에서는 최대 5개까지의 SDA를 생성할 수 있습니다.","Token의 제한 값이 변경된 이후 moreh-smi device --add 명령어로 SDA를 추가할 수 있습니다.","다음은 SDA를 추가하는 예제입니다.","moreh-smi device --add 커맨드를 입력하면 moreh-switch-model 과 동일한 인터페이스가 나타납니다. 1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “Create device success.” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA가 생성됩니다. 여기서는 3번 Large.256GB 로 SDA를 하나 더 생성해 보겠습니다.","moreh-smi device --add {model_id} 명령어를 통해 대화형 입력창 없이 바로 SDA를 생성할 수도 있습니다.","여기서 {model_id} 는 SDA 모델의 번호를 의미하며, Large.256GB 의 경우에는 ‘3’ 이 됩니다."]},{"i":"7-생성된-sda-디바이스-삭제하기-moreh-smi-device---rm","l":"7. 생성된 SDA 디바이스 삭제하기 moreh-smi device --rm","p":["생성된 SDA 디바이스를 삭제하려면 moreh-smi device --rm 명령어를 사용하면 됩니다.","moreh-smi device --rm {Device_ID} 명령어로 특정 Device_ID에 해당하는 SDA를 삭제해보겠습니다.","만약 help message에 device --add 와 같은 옵션의 도움말이 등장하지 않는다면 사용자 token에 대한 최대 디바이스 개수가 1로 설정된 것이므로 고객지원을 요청 부탁드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"l":"8. SDA 생성된 디바이스 기본값 변경하기","p":["moreh-smi device --switch {Device_ID} 명령어를 입력하면 이미 생성된 디바이스의 ID에 해당하는 디바이스로 변경됩니다.","moreh-smi device --switch {Device_ID} 를 통해 0번 Medium.128GB 을 기본 SDA로 변경해 보겠습니다.","생성된 SDA 모델 리스트 중 디바이스에 해당하는 정수를 입력하면 “Switch current device success.” 메시지와 함께 입력된 SDA가 기본 디바이스로 설정됩니다. 학습 프로세스 실행하면 설정한 기본 SDA 디바이스를 사용합니다.","여기서는 다시 1번 Medium.128GB 을 기본 SDA 디바이스로 변경해 보겠습니다.","이제 학습 실행 시 기본 값으로 1번 디바이스를 사용하게 됩니다."]}],[{"i":"gpu-자원-변경하기-moreh-switch-model","l":"GPU 자원 변경하기 (moreh-switch-model)","p":["VM에서 사용할 GPU의 개수를 조정할 수 있습니다. 다음 명령어(moreh-switch-model)를 통해 SDA를 변경할 수 있습니다.","현재 지원하는 SDA는 다음(Figure 1)과 같습니다. 번호로 SDA을 선택할수있고, q(또는 Q)로 대화를 종료 할 수 있습니다.","제일 작은 단위의 SDA는 Small.64GB이며 총 64GB 메모리를 가지고 있습니다. 그 이상 SDA는 Small.64GB의 배수만큼의 계산능력과 메모리를 가집니다. 예를 들어 Large.256GB는 Small.64GB에 비해 4배의 계산능력과 메모리를 가집니다."]}],[{"i":"moreh-솔루션-업데이트-하기-update-moreh","l":"Moreh 솔루션 업데이트 하기 (update-moreh)","p":["Moreh 솔루션은 주기적으로 업데이트되면서 솔루션의 전반적 성능이 개선되고 있습니다. Moreh 솔루션을 활용하는 방식에 따라 특정 버전의 Moreh 솔루션만을 사용하실 수 있지만, 가급적 최신 Moreh 솔루션을 사용하시는 것을 권장하고 있습니다. Moreh 솔루션을 업데이트하시면 사용하시는 환경의 Deep learning framework(PyTorch, TensorFlow) 및 Moreh driver 등의 필수 패키지들이 업데이트됩니다.","Moreh 솔루션은 다음 명령어를 통해 업데이트하실 수 있습니다.","기본적으로 위 명령어 실행 시 현재까지 배포된 버전 중 최신 버전으로 업데이트를 진행합니다.","-target","Moreh 솔루션을 특정 버전으로 다운(업)그레이드를 할 수 있는 옵션입니다. --target 옵션 뒤에는 특정 버전을 아래와 같이 기입해주시면 됩니다."]},{"l":"Deep Learning Framework 버전 변경하기","p":["Moreh 솔루션은 Pytorch 1.7.1 버전뿐만이 아닌 Pytorch 1.10.0, 1.13.1 버전과 Tensorflow 2.9.0 버전에 대해서도 제공하고 있습니다.","다른 버전의 Framework 설치를 위한 옵션은 다음과 같습니다."]},{"l":"PyTorch 버전 변경하기"},{"l":"TensorFlow 버전 변경하기","p":["\uD83D\uDCA1 Tensorflow와 Pytorch 1.10.0 혹은 1.13.1 버전은 동시에 설치를 할 수 없습니다."]}],[{"l":"K8S Cluster에서 Moreh 솔루션 사용하기"},{"l":"K8S Cluster에 접근하기 위한 서버 접속","p":["K8S Cluster를 사용하기 위해 moreh-k8s-master-vm01 서버로 접속해야합니다.","관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","관리자가 해당 VM 접속정보를 이용자에게 제공하였다고 가정해보겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"Pod을 띄우기 위한 Manifest 파일 작성","p":["$ kubectl apply -f {파일 경로}","$ kubectl exec -it {pod 이름} -n {namespace} -c {container 이름} -- /bin/bash","$ kubectl get pods -n {metadata.namespace}","apply: 해당 액션으로 쿠버네티스 리소스를 생성/수정","f: 파일 경로","K8S 클러스터 안에서 pod을 띄우기 위해 다음과 같이 작성합니다.","K8S 클러스터에 pod을 생성하기 위해 다음의 명령어로 위에서 작성한 manifest 파일을 적용합니다.","K8S 클러스터에 해당 pod이 생성되었는지 다음의 명령어로 확인합니다.","Manifest 파일은 쿠버네티스 오브젝트를 관리하기 위한 선언적 specification을 포함하는 YAML 파일입니다.","metadata.name: pod의 이름","spec.template.spec.containers[0].env[0].value: 사용할 토큰","spec.template.spec.containers[0].image: Moreh 솔루션의 도커 이미지","spec.template.spec.containers[0].name: container의 이름","먼저 모레 솔루션이 작동하는지 여부를 moreh toolkit을 활용해 확인해봅니다.","사용자가 작성해야 할 주요 key는 다음과 같습니다.","생성한 pod에 다음의 명령어로 접속합니다."]},{"l":"Moreh Toolkit 사용","p":["moreh-smi","moreh-switch-model","만약 moreh tools를 실행했을 때 다음과 같이 ‘moreh::InvalidToken’ 에러가 발생한 경우 토큰 설정을 해주어야 합니다.","컨테이너 내부에서 /etc/moreh/token 에 할당받은 토큰을 입력하면 위의 문제가 해결됩니다."]},{"l":"Duplicable SDA 설정","p":["추론 시스템을 구축하는 경우, 하나의 SDA에서 여러 프로세스를 만들 필요가 있을 수 있습니다. 이러한 경우 duplicable SDA 설정을 통해 하나의 SDA에서 다수의 GPU 활용 프로그램을 실행할 수 있습니다.","Duplicable SDA는 moreh-smclient 를 통해 설정할 수 있습니다."]},{"l":"PyTorch 학습","p":["샘플 코드인 pytorch-sample.py를 사용해 학습을 진행하면 다음과 같은 결과를 얻을 수 있습니다."]},{"l":"사용 완료한 Pod 제거","p":["pod을 제거하기 위해서는 먼저 deployment를 삭제해야합니다.","$ kubectl delete pod {pod 이름} -n {namespace} 로 pod을 삭제하면 deployment 컨트롤러가 새 pod을 생성하여 복제본 수를 유지하려고 하기 때문입니다.","다음의 명령어로 deployment를 삭제합니다.","$ kubectl delete deployment {deployment 이름} -n {namespace}","그 후 pod을 제거합니다.","$ kubectl delete pod {pod 이름} -n {namespace}","pod이 삭제되었는지 확인합니다.","$ kubectl get pods -n {namespace}"]}],[{"l":"Troubleshooting","p":["Moreh 솔루션 사용 시 발생할 수 있는 일반적인 오류에 대한 해결 방안을 제공합니다."]},{"i":"two-or-more-processes-cannot-use-kt-ai-accelerator-at-the-same-time","l":"Two or more processes cannot use KT AI Accelerator at the same time.","p":["SDA가 이미 사용 중인 경우, Two or more processes cannot use KT AI Accelerator at the same time. 경고 메시지가 출력될 수 있습니다. moreh-smi --reset 명령을 실행하여 강제로 SDA를 해제할 수 있습니다. 동일한 토큰 값으로 여러 개의 Pod를 띄워 SDA를 동시에 사용하려는 경우(e.g., K8s 기반 서비스) KT Cloud에 문의하여 토큰의 duplicable 설정을 받으시기 바랍니다.","moreh-smi --reset 으로 강제로 SDA 해제"]},{"i":"morehinvalidtoken","l":"moreh::InvalidToken.","p":["SDA 토큰이 적용되지 않아 발생하는 오류 메시지입니다. 환경 변수 MOREH_SDA_TOKEN 를 할당받은 토큰으로 설정한 후, 모레 솔루션을 사용하시면 해당 오류가 해결됩니다."]},{"i":"update-moreh---tensorflow-명령줄-실행-시-업데이트가-진행되지-않거나-python-패키지가-잡히지-않는-경우","l":"update-moreh --tensorflow 명령줄 실행 시 업데이트가 진행되지 않거나 Python 패키지가 잡히지 않는 경우.","p":["해당 문제는 .local 폴더와 관련된 문제일 수 있습니다. 해당 폴더 ~/.local/lib 과 ~/.local/bin 을 삭제 후 재시도해보시기 바랍니다."]},{"l":"사용자 VM에서 Python 프로세스가 종료되지 않고 남아있는 경우","p":["모델 학습을 강제 중단 혹은 종료한다면 비정상 종료된 Python 프로세스가 종료되지 않고 남아있을 수 있습니다.","pkill python 혹은 vkill {pid} 를 통해 종료하시길 바랍니다."]},{"l":"SSH 클라이언트와 통신이 끊겨 학습이 종료되는 경우","p":["보안을 위해 일정 시간 터미널에서 동작이 없다면 SSH 클라이언트와 통신이 끊기게 됩니다.","위와 같이 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"i":"2380-이전-버전을-update-moreh-명령어로-설치할-때-moreh-솔루션이-제대로-설치되지-않는-경우","l":"23.8.0 이전 버전을 update-moreh 명령어로 설치할 때 Moreh 솔루션이 제대로 설치되지 않는 경우","p":["update-moreh 명령어 외에 파이썬 패키지 관리자인 pip을 사용하여 Moreh 솔루션을 동일하게 업데이트할 수 있습니다.","update-moreh 로 솔루션 설치가 제대로 이루어지지 않는다면 다음의 pip install 을 통해 솔루션을 설치해보시기 바랍니다."]},{"l":"Moreh 솔루션 버전을 roll back하려 할 때 update-moreh가 제대로 동작하지 않는 경우","p":["동일한 버전으로 다시 Moreh 솔루션을 설치하고 싶은 경우나, 원하는 타깃 버전으로 업(다운)그레이드가 정상적으로 되지 않을 경우 -force 옵션을 통해 강제로 Moreh 솔루션의 업데이트를 진행할 수 있습니다.","하지만 가급적이면 Moreh 솔루션 사용시 -force command는 지양하고 있으니 버전이슈로 인한 에러가 발생한 경우 고객지원을 요청 바랍니다."]}],[{"i":"#","p":["MoAI Platform은 다양한 GPU로 구성될 수 있지만, 동일한 인터페이스(CLI)를 통해 사용자에게 일관된 경험을 제공합니다. 모든 사용자가 같은 방식으로 시스템에 접근하여 플랫폼을 사용할 수 있기 때문에 보다 효율적이며 직관적입니다.","MoAI Platform 또한 일반적인 AI 학습 환경과 유사하게 Python 기반의 프로그래밍을 지원합니다. 이에 따라 본 문서에서는 AI 학습을 위한 표준 환경 구성으로서 conda 가상 환경의 설정과 사용 방법을 중심으로 설명합니다."]},{"l":"conda 환경 설정하기","p":["훈련을 시작하기 위해 먼저 conda 환경을 생성합니다.","my-env 에는 사용자가 사용할 환경 이름을 입력합니다.","conda 환경을 활성화합니다.","Fine-tuning에 필요한 library와 package를 설치합니다.","moreh-smi 명령어를 입력해 설치된 Moreh 솔루션의 버전과 사용중인 MoAI Accelerator 정보를 확인할 수 있습니다. 현재 사용중인 MoAI Accelerator는 4xLarge.2048GB 입니다. MoAI Accelerator에 대한 자세한 정보는 MoAI Accelerator 사양을 참고해주세요."]},{"i":"moai-accelerator-선택-변경하기","l":"MoAI Accelerator 선택, 변경하기","p":["sLLM 파인튜닝시 학습 데이터 배치 사이즈에 따른 적절한 MoAI Accelerator 모델을 moreh toolkit을 사용하여 선택, 변경할 수 있습니다. 참고로, sLLM(약 7B~ 13B 모델)을 fine-tuning 하기 위해 일반적으로 사용되는 데이터셋의 크기는 약 40GB의 텍스트 데이터셋입니다.","먼저, moreh-smi 를 사용하여 현재 사용하고 있는 MoAI Accelerator 모델을 확인해 보겠습니다.","현재 사용하고 있는 MoAI Accelerator 모델에서 제공되는 메모리는 64GB입니다. moreh-switch-model 을 사용하여 더 큰 메모리를 제공하는 MoAI Accelerator 모델로 변경해 보겠습니다.","4xLarge.2048GB 모델로 변경하기 위해 8 을 입력합니다.","q 를 입력하여 변경을 완료합니다.","다시 moreh-smi 를 사용하여 변경된 상태를 확인하면 사용하고 있는 MoAI Accelerator 모델이 4xLarge.2048GB 모델로 변경된 것을 확인할 수 있습니다."]}],[{"l":"LLM Fine tuning 파라미터 가이드","p":["1,122,745 MiB","1,138,546 MiB","1,403,047 MiB","1,651,008 MiB","1,680,233 MiB","1,706,797 MiB","1,764,955 MiB","1,767,888 MiB","1,800,656 MiB","1024","109872","11,562","11m","121,013","125,180","128","1292886 MiB","12m","13286","1360m","13m","1403,2189","144,124","1467646 MiB","1489,3","15,890","15,972","154,12123","157,859","16","1600235 MiB","163,839","172395","17m","186,353","191605","194,282","2,146,115 MiB","2,645,347 MiB","2,800,000 MiB","2,845,656 MiB","2048","20m","22m","238,212","24,156","24.2.0","24.3.0","24.5.0","24m","256","25m","26,111","27B","28m","2xlarge","3,460,240 MiB","3013826 MiB","30m","3143781 MiB","3181616 MiB","32","32,371","32,563","34m","35m","36m","376,493","38m","400m","4096","40m","442,982 MiB","47,679","480m","4xlarge","50,782","51,353","512","543816 MiB","56,385","560,835 MiB","560m","58531","586m","59m","62,481","62,582","62,740","626,391 MiB","62m","63,893","638,460 MiB","64","65,565","6841","69,840","720m","749065 MiB","784,485 MiB","790,572 MiB","790454 MiB","7m","8,934","81m","843,375 MiB","858,128 MiB","866,656 MiB","872m","8m","8xlarge","92,623","93,165","962m","99,873","9m","Advanced Parallelism 적용 유무","Baichuan2 13B","batch size","Cerebras GPT 13B","Llama2 13B","Mistral 7B","MoAI Accelerator","MoAI Accelerator 에 명시된 명칭은 사용자가 이용하는 CSP에 따라 다를 수 있습니다.","MoAI Platform version","Qwen1.5 7B","sequence length","throughput","token 갯수","True","vram 사용량","모델명","학습 시간"]}]]